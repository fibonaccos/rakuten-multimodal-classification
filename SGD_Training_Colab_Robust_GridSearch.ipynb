# ===== Installation et imports =====
!pip install -q scikit-learn matplotlib seaborn

import numpy as np
import pandas as pd
import sklearn
import os
import json
import pickle
import joblib
import warnings
from datetime import datetime
import time
import zipfile
from google.colab import drive, files
from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import product

warnings.filterwarnings("ignore")
print("Versions -> NumPy:", np.__version__, "| scikit-learn:", sklearn.__version__)
print("üîß Version corrig√©e avec GridSearch par √©tapes")

# ===== Montage Drive et Configuration =====
drive.mount("/content/drive")
PROJECT_PATH = "/content/drive/MyDrive/rakuten-multimodal-classification"  # adapter si besoin
os.chdir(PROJECT_PATH)
print("PWD:", os.getcwd())

for d in ["models", "reports", "reports/figures", "logs", "data/processed", "checkpoints"]:
    os.makedirs(d, exist_ok=True)

config = {
    "TRAINING": {
        "SGD": {
            "DATA_PATH": "data/processed/features_for_dt.csv",
            "PREPROCESSING": {
                "normalize": True,
                "remove_constant_features": True,
                "handle_missing": True,
                "feature_selection": True
            },
            "GRID_SEARCH": {
                "active": True,
                "param_grid": {
                    "loss": ["log_loss", "modified_huber", "hinge"],
                    "alpha": [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],
                    "learning_rate": ["constant", "optimal"],
                    "eta0": [0.001, 0.01, 0.1],
                    "class_weight": [None, "balanced"]
                },
                "cv_folds": 5,
                "scoring": "f1_weighted",
                "n_jobs": -1,
                "batch_size": 10,  # NOUVEAU: traiter par lots de N combinaisons
                "save_interval": 5  # NOUVEAU: sauvegarder toutes les N combinaisons
            },
            "MODEL_PARAMS": {
                "max_iter": 5000,
                "tol": 1e-5,
                "random_state": 42,
                "early_stopping": True,
                "validation_fraction": 0.1,
                "n_iter_no_change": 10
            },
            "EVALUATION": {
                "test_size": 0.2,
                "random_state": 42,
                "stratify": True
            }
        }
    }
}
print("‚úÖ Configuration am√©lior√©e charg√©e avec GridSearch par √©tapes")

# ===== Classe SGDTrainer avec GridSearch Robuste =====
class SGDTrainerFixedWithCheckpoints:
    def __init__(self, cfg):
        self.cfg = cfg
        self.checkpoint_dir = "checkpoints"
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        self.checkpoint_file = self._find_latest_checkpoint() or f"{self.checkpoint_dir}/sgd_checkpoint_fixed_{datetime.now().strftime('%y%m%d-%H%M%S')}.pkl"
        self.ts = self._extract_ts_from_checkpoint(self.checkpoint_file)
        self.model = None
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.feature_selector = VarianceThreshold(threshold=1e-6)
        self.X_train = self.X_test = self.y_train = self.y_test = None
        self.results = {}
        self.best_params = None
        self.pipeline = None
        self.steps = [
            'data_loaded',
            'preprocessing_done',
            'grid_setup_done',
            'optimization_done',
            'training_done',
            'evaluation_done',
            'reports_done'
        ]
        self.state = {step: False for step in self.steps}
        self.step_names = {
            'data_loaded': 'Chargement des donn√©es',
            'preprocessing_done': 'Preprocessing',
            'grid_setup_done': 'Setup GridSearch',
            'optimization_done': 'Optimisation GridSearch',
            'training_done': 'Entra√Ænement final',
            'evaluation_done': '√âvaluation du mod√®le',
            'reports_done': 'G√©n√©ration des rapports'
        }
        self.grid_results = []
        self.best_score = -np.inf
        self.current_batch = 0
        self.total_combinations = 0
        self.param_combinations = []
        print(f"üöÄ Init trainer: {self.ts}")
        self._load_checkpoint()
        # Correction : synchronisation des cl√©s de self.state avec self.steps
        for step in self.steps:
            if step not in self.state:
                self.state[step] = False
        self._print_progress()

    def _find_latest_checkpoint(self):
        """Trouve le dernier checkpoint dans le dossier"""
        files = [f for f in os.listdir(self.checkpoint_dir) if f.startswith('sgd_checkpoint_fixed_') and f.endswith('.pkl')]
        if not files:
            return None
        files = sorted(files, reverse=True)
        return os.path.join(self.checkpoint_dir, files[0])

    def _extract_ts_from_checkpoint(self, checkpoint_file):
        """Extrait le timestamp du nom du checkpoint"""
        try:
            base = os.path.basename(checkpoint_file)
            ts = base.replace('sgd_checkpoint_fixed_', '').replace('.pkl', '')
            return ts
        except:
            return datetime.now().strftime('%y%m%d-%H%M%S')

    def _load_checkpoint(self):
        if os.path.exists(self.checkpoint_file):
            try:
                with open(self.checkpoint_file, 'rb') as f:
                    data = pickle.load(f)
                self.state = data['state']
                self.results = data['results']
                self.best_params = data['best_params']
                self.X_train = data['X_train']
                self.X_test = data['X_test']
                self.y_train = data['y_train']
                self.y_test = data['y_test']
                self.label_encoder = data['label_encoder']
                self.scaler = data.get('scaler', StandardScaler())
                self.feature_selector = data.get('feature_selector', VarianceThreshold(threshold=1e-6))
                self.model = data['model']
                save_time = data.get('timestamp', 'inconnu')
                print(f"üîÑ Checkpoint restaur√© (sauv√© le: {save_time})")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur checkpoint: {e}")

    def _print_progress(self):
        completed = sum(self.state.values())
        total = len(self.steps)
        percentage = (completed / total) * 100
        print(f"\nüìä PROGRESSION GLOBALE: {percentage:.1f}% ({completed}/{total})")
        print("=" * 50)
        for step in self.steps:
            status = "‚úÖ" if self.state[step] else "‚è≥"
            print(f"{status} {self.step_names[step]}")

        # Afficher progression GridSearch si en cours
        if hasattr(self, 'grid_results') and len(self.grid_results) > 0:
            tested = len(self.grid_results)
            total_combs = self.total_combinations if self.total_combinations > 0 else tested
            grid_progress = (tested / total_combs) * 100 if total_combs > 0 else 0
            print(f"üîç GridSearch: {tested}/{total_combs} combinaisons test√©es ({grid_progress:.1f}%)")
            if self.best_score > -np.inf:
                print(f"üèÜ Meilleur score actuel: {self.best_score:.4f}")
        print("=" * 50)

    def _update_progress(self, step_name, substep="", progress=None):
        if progress is not None:
            bar_length = 30
            filled = int(bar_length * progress / 100)
            bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)
            print(f"‚è≥ {step_name} {substep}: [{bar}] {progress:.1f}%", end="\r")
        else:
            print(f"‚è≥ {step_name} {substep}")

    def _save_checkpoint(self):
        checkpoint_data = {
            'state': self.state,
            'results': self.results,
            'best_params': self.best_params,
            'best_score': self.best_score,
            'ts': self.ts,
            'X_train': self.X_train,
            'X_test': self.X_test,
            'y_train': self.y_train,
            'y_test': self.y_test,
            'label_encoder': self.label_encoder,
            'scaler': self.scaler,
            'feature_selector': self.feature_selector,
            'model': self.model,
            'grid_results': self.grid_results,
            'current_batch': self.current_batch,
            'total_combinations': self.total_combinations,
            'param_combinations': self.param_combinations,
            'timestamp': datetime.now().isoformat()
        }
        with open(self.checkpoint_file, 'wb') as f:
            pickle.dump(checkpoint_data, f)
        file_size = os.path.getsize(self.checkpoint_file) / (1024 * 1024)
        print(f"\nüíæ Checkpoint sauv√© ({file_size:.1f} MB)")

    def load_data(self):
        if self.state['data_loaded']:
            print("‚úÖ Donn√©es d√©j√† charg√©es")
            return
        print(f"\nüéØ √âTAPE 1/7: {self.step_names['data_loaded']}")
        start_time = time.time()
        path = self.cfg["TRAINING"]["SGD"]["DATA_PATH"]
        self._update_progress("Chargement", "Lecture du CSV", 20)
        df = pd.read_csv(path)
        self._update_progress("Chargement", "Identification target", 40)

        if "label" in df.columns:
            target = "label"
        else:
            target_candidates = [col for col in df.columns if df[col].nunique() == 27]
            if target_candidates:
                target = target_candidates[0]
            else:
                raise ValueError("Impossible de trouver la colonne target avec 27 classes")

        self._update_progress("Chargement", "S√©paration X/y", 60)
        X = df.drop(columns=[target])
        y = df[target]

        print(f"\nüìä Diagnostic initial:")
        print(f"   Forme: {X.shape}")
        print(f"   Classes: {y.nunique()}")
        print(f"   Distribution: min={y.value_counts().min()}, max={y.value_counts().max()}")
        print(f"   Ratio d√©s√©quilibre: {y.value_counts().max() / y.value_counts().min():.1f}:1")

        self._update_progress("Chargement", "Encodage labels", 80)
        y_enc = self.label_encoder.fit_transform(y)

        self._update_progress("Chargement", "Split train/test", 90)
        ev = self.cfg["TRAINING"]["SGD"]["EVALUATION"]
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y_enc,
            test_size=ev["test_size"],
            random_state=ev["random_state"],
            stratify=y_enc if ev["stratify"] else None
        )

        elapsed = time.time() - start_time
        print(f"\n‚úÖ Donn√©es charg√©es en {elapsed:.1f}s")
        print(f"   Train: {self.X_train.shape}, Test: {self.X_test.shape}")
        self.state['data_loaded'] = True
        self._save_checkpoint()
        self._print_progress()

    def preprocess_data(self):
        if self.state['preprocessing_done']:
            print("‚úÖ Preprocessing d√©j√† effectu√©")
            return
        print(f"\nüéØ √âTAPE 2/7: {self.step_names['preprocessing_done']}")
        start_time = time.time()

        # Suppression features constantes
        self._update_progress("Preprocessing", "Suppression features constantes", 20)
        constant_features = [col for col in self.X_train.columns if self.X_train[col].nunique() <= 1]
        if constant_features:
            print(f"\nüßπ Suppression de {len(constant_features)} features constantes")
            self.X_train = self.X_train.drop(columns=constant_features)
            self.X_test = self.X_test.drop(columns=constant_features)

        # S√©lection par variance
        self._update_progress("Preprocessing", "S√©lection par variance", 40)
        X_train_selected = self.feature_selector.fit_transform(self.X_train)
        X_test_selected = self.feature_selector.transform(self.X_test)
        n_features_removed = self.X_train.shape[1] - X_train_selected.shape[1]
        if n_features_removed > 0:
            print(f"\nüßπ Suppression de {n_features_removed} features √† faible variance")

        # Normalisation StandardScaler (CRITIQUE)
        self._update_progress("Preprocessing", "Normalisation StandardScaler", 70)
        X_train_scaled = self.scaler.fit_transform(X_train_selected)
        X_test_scaled = self.scaler.transform(X_test_selected)

        mean_check = np.abs(X_train_scaled.mean(axis=0)).max()
        std_check = X_train_scaled.std(axis=0).max()
        print(f"\n‚úÖ Normalisation v√©rifi√©e:")
        print(f"   Moyenne max: {mean_check:.6f} (doit √™tre ~0)")
        print(f"   Std max: {std_check:.6f} (doit √™tre ~1)")

        self.X_train = X_train_scaled
        self.X_test = X_test_scaled

        elapsed = time.time() - start_time
        print(f"\n‚úÖ Preprocessing termin√© en {elapsed:.1f}s")
        print(f"   Features finales: {self.X_train.shape[1]}")

        self.state['preprocessing_done'] = True
        self._save_checkpoint()
        self._print_progress()

    def setup_grid_search(self):
        """Pr√©pare toutes les combinaisons de param√®tres pour le GridSearch par √©tapes"""
        if self.state['grid_setup_done']:
            print("‚úÖ Setup GridSearch d√©j√† effectu√©")
            return

        print(f"\nüéØ √âTAPE 3/7: {self.step_names['grid_setup_done']}")

        gs_cfg = self.cfg["TRAINING"]["SGD"]["GRID_SEARCH"]
        if not gs_cfg["active"]:
            print("‚è≠Ô∏è GridSearch d√©sactiv√©")
            self.state['grid_setup_done'] = True
            self.state['optimization_done'] = True
            self._save_checkpoint()
            return

        # G√©n√©rer toutes les combinaisons
        param_names = list(gs_cfg["param_grid"].keys())
        param_values = list(gs_cfg["param_grid"].values())

        self.param_combinations = []
        for combination in product(*param_values):
            param_dict = dict(zip(param_names, combination))
            self.param_combinations.append(param_dict)

        self.total_combinations = len(self.param_combinations)
        batch_size = gs_cfg.get("batch_size", 10)

        print(f"üîç GridSearch Setup:")
        print(f"   Total combinaisons: {self.total_combinations}")
        print(f"   Taille des lots: {batch_size}")
        print(f"   Nombre de lots: {(self.total_combinations + batch_size - 1) // batch_size}")
        print(f"   CV folds: {gs_cfg['cv_folds']}")

        # Estimer le temps par combinaison (plus conservateur pour Colab)
        estimated_time_per_combo = 30  # secondes
        total_estimated_minutes = (self.total_combinations * estimated_time_per_combo) / 60
        print(f"   Temps estim√© total: ~{total_estimated_minutes:.1f} minutes")
        print(f"   Temps par lot: ~{(batch_size * estimated_time_per_combo)/60:.1f} minutes")

        self.state['grid_setup_done'] = True
        self._save_checkpoint()
        self._print_progress()

    def optimize_batch(self):
        """Optimise le mod√®le par lots de combinaisons avec checkpoints fr√©quents"""
        if self.state['optimization_done']:
            print("‚úÖ Optimisation d√©j√† effectu√©e")
            return

        if not self.state['grid_setup_done']:
            self.setup_grid_search()

        print(f"\nüéØ √âTAPE 4/7: {self.step_names['optimization_done']}")

        gs_cfg = self.cfg["TRAINING"]["SGD"]["GRID_SEARCH"]
        batch_size = gs_cfg.get("batch_size", 10)
        save_interval = gs_cfg.get("save_interval", 5)

        # Reprendre o√π on s'√©tait arr√™t√©
        start_idx = len(self.grid_results)
        remaining_combinations = self.param_combinations[start_idx:]

        if len(remaining_combinations) == 0:
            print("‚úÖ Toutes les combinaisons ont d√©j√† √©t√© test√©es")
            self.state['optimization_done'] = True
            self._save_checkpoint()
            return

        print(f"üîÑ Reprise GridSearch: {start_idx}/{self.total_combinations} combinaisons d√©j√† test√©es")
        print(f"üìä Reste √† tester: {len(remaining_combinations)} combinaisons")

        base_params = self.cfg["TRAINING"]["SGD"]["MODEL_PARAMS"].copy()

        start_time = time.time()
        last_save_time = start_time

        for i, params in enumerate(remaining_combinations):
            current_idx = start_idx + i
            print(f"\nüîç Test {current_idx + 1}/{self.total_combinations}: {params}")

            try:
                # Cr√©er le mod√®le avec les param√®tres actuels
                model_params = base_params.copy()
                model_params.update(params)

                clf = SGDClassifier(**model_params)

                # Cross-validation
                cv_start = time.time()
                scores = cross_val_score(
                    clf, self.X_train, self.y_train,
                    cv=gs_cfg["cv_folds"],
                    scoring=gs_cfg["scoring"],
                    n_jobs=1  # √âviter les probl√®mes de m√©moire sur Colab
                )
                cv_time = time.time() - cv_start

                mean_score = scores.mean()
                std_score = scores.std()

                # Enregistrer le r√©sultat
                result = {
                    'params': params.copy(),
                    'mean_test_score': mean_score,
                    'std_test_score': std_score,
                    'individual_scores': scores.tolist(),
                    'cv_time': cv_time,
                    'timestamp': datetime.now().isoformat()
                }

                self.grid_results.append(result)

                # Mettre √† jour le meilleur score
                if mean_score > self.best_score:
                    self.best_score = mean_score
                    self.best_params = params.copy()
                    print(f"üèÜ NOUVEAU MEILLEUR SCORE: {mean_score:.4f} (¬±{std_score:.4f})")
                    print(f"üîß Param√®tres: {params}")
                else:
                    print(f"üìä Score: {mean_score:.4f} (¬±{std_score:.4f}) - temps: {cv_time:.1f}s")

                # Sauvegarde p√©riodique
                if (i + 1) % save_interval == 0 or time.time() - last_save_time > 300:  # Toutes les 5 min minimum
                    self._save_checkpoint()
                    last_save_time = time.time()

                    elapsed = time.time() - start_time
                    remaining = len(remaining_combinations) - i - 1
                    if remaining > 0:
                        eta = (elapsed / (i + 1)) * remaining
                        print(f"‚è±Ô∏è Progression: {i+1}/{len(remaining_combinations)} - ETA: {eta/60:.1f} min")

                # Pause pour √©viter la surcharge
                time.sleep(1)

            except Exception as e:
                print(f"‚ùå Erreur avec {params}: {e}")
                # Continuer avec les autres combinaisons
                continue

        # Sauvegarde finale
        self.state['optimization_done'] = True
        self._save_checkpoint()

        elapsed = time.time() - start_time
        print(f"\n‚úÖ GridSearch termin√© en {elapsed/60:.1f} minutes")
        print(f"üèÜ Meilleur score: {self.best_score:.4f}")
        print(f"üîß Meilleurs param√®tres: {self.best_params}")

        # Afficher le top 5
        sorted_results = sorted(self.grid_results, key=lambda x: x['mean_test_score'], reverse=True)
        print(f"\nüìä TOP 5 COMBINAISONS:")
        for i, result in enumerate(sorted_results[:5]):
            print(f"   {i+1}. Score: {result['mean_test_score']:.4f} - {result['params']}")

        self._print_progress()

    def fit_final(self):
        if self.state['training_done']:
            print("‚úÖ Entra√Ænement final d√©j√† effectu√©")
            return
        print(f"\nüéØ √âTAPE 5/7: {self.step_names['training_done']}")
        start_time = time.time()

        if self.best_params is None:
            print("‚ö†Ô∏è Aucuns meilleurs param√®tres trouv√©s, utilisation des param√®tres par d√©faut")
            params = self.cfg["TRAINING"]["SGD"]["MODEL_PARAMS"].copy()
        else:
            params = self.cfg["TRAINING"]["SGD"]["MODEL_PARAMS"].copy()
            params.update(self.best_params)

        print(f"üîß Param√®tres finaux: {params}")

        self.model = Pipeline([
            ('sgd', SGDClassifier(**params))
        ])

        try:
            self._update_progress("Entra√Ænement", "Sur donn√©es normalis√©es", 50)
            self.model.fit(self.X_train, self.y_train)

            sgd_model = self.model.named_steps['sgd']
            n_iter = getattr(sgd_model, 'n_iter_', 'N/A')

            elapsed = time.time() - start_time
            print(f"\n‚úÖ Entra√Ænement termin√© en {elapsed:.1f}s")
            print(f"üìà Nombre d'it√©rations: {n_iter}")

            self.state['training_done'] = True
            self._save_checkpoint()
            self._print_progress()

        except Exception as e:
            print(f"‚ùå Erreur entra√Ænement: {e}")
            raise

    def evaluate(self):
        if self.state['evaluation_done']:
            print("‚úÖ √âvaluation d√©j√† effectu√©e")
            return self.results.get("classification_report"), self.results.get("confusion_matrix")

        print(f"\nüéØ √âTAPE 6/7: {self.step_names['evaluation_done']}")
        start_time = time.time()

        try:
            self._update_progress("√âvaluation", "Pr√©dictions", 50)
            ytr_pred = self.model.predict(self.X_train)
            yte_pred = self.model.predict(self.X_test)

            self.results.update({
                "train_accuracy": accuracy_score(self.y_train, ytr_pred),
                "test_accuracy": accuracy_score(self.y_test, yte_pred),
                "train_f1": f1_score(self.y_train, ytr_pred, average="weighted"),
                "test_f1": f1_score(self.y_test, yte_pred, average="weighted"),
                "best_cv_score": self.best_score,
                "grid_search_results": self.grid_results[-10:] if len(self.grid_results) > 10 else self.grid_results
            })

            cr = classification_report(self.y_test, yte_pred,
                                     target_names=[str(cls) for cls in self.label_encoder.classes_],
                                     output_dict=True)
            cm = confusion_matrix(self.y_test, yte_pred)

            self.results["classification_report"] = cr
            self.results["confusion_matrix"] = cm.tolist()
            self.results["class_names"] = [str(cls) for cls in self.label_encoder.classes_]

            elapsed = time.time() - start_time
            print(f"\n‚úÖ √âvaluation termin√©e en {elapsed:.1f}s")
            print(f"üìä R√âSULTATS FINAUX:")
            print(f"   Accuracy: {self.results['test_accuracy']:.4f}")
            print(f"   F1-score: {self.results['test_f1']:.4f}")
            print(f"   Meilleur CV score: {self.best_score:.4f}")

            unique_preds = len(np.unique(yte_pred))
            print(f"   Classes pr√©dites: {unique_preds}/27")

            self.state['evaluation_done'] = True
            self._save_checkpoint()
            self._print_progress()
            return cr, cm

        except Exception as e:
            print(f"‚ùå Erreur √©valuation: {e}")
            raise

    def save(self):
        print("üíæ Sauvegarde des mod√®les...")
        mp = f"models/sgd_classifier_robust_{self.ts}.pkl"
        ep = f"models/sgd_label_encoder_robust_{self.ts}.pkl"
        sp = f"models/sgd_scaler_robust_{self.ts}.pkl"
        fp = f"models/sgd_feature_selector_robust_{self.ts}.pkl"
        gp = f"models/sgd_grid_results_robust_{self.ts}.json"

        joblib.dump(self.model, mp)
        joblib.dump(self.label_encoder, ep)
        joblib.dump(self.scaler, sp)
        joblib.dump(self.feature_selector, fp)

        # Sauvegarder les r√©sultats du GridSearch
        with open(gp, 'w') as f:
            json.dump({
                'best_params': self.best_params,
                'best_score': self.best_score,
                'all_results': self.grid_results,
                'total_combinations_tested': len(self.grid_results),
                'timestamp': datetime.now().isoformat()
            }, f, indent=2)

        return mp, ep, sp, fp, gp

    def reports(self, cr, cm):
        if self.state['reports_done']:
            print("‚úÖ Rapports d√©j√† g√©n√©r√©s")
            return

        print(f"\nüéØ √âTAPE 7/7: {self.step_names['reports_done']}")
        start_time = time.time()

        try:
            # Rapport texte
            rep_txt = f"reports/sgd_classification_report_robust_{self.ts}.txt"
            with open(rep_txt, "w") as f:
                f.write("=== RAPPORT SGD ROBUSTE (GridSearch par √©tapes) ===\n")
                f.write(f"Timestamp: {self.ts}\n")
                f.write(f"Features finales: {self.X_train.shape[1]}\n")
                f.write(f"Combinaisons test√©es: {len(self.grid_results)}/{self.total_combinations}\n\n")
                f.write("M√âTRIQUES PRINCIPALES:\n")
                f.write(json.dumps({
                    "train_accuracy": self.results["train_accuracy"],
                    "test_accuracy": self.results["test_accuracy"],
                    "train_f1": self.results["train_f1"],
                    "test_f1": self.results["test_f1"],
                    "best_params": self.best_params,
                    "best_cv_score": self.best_score
                }, indent=2))
                f.write("\n\nRAPPORT D√âTAILL√â:\n")
                f.write(classification_report(
                    self.y_test, self.model.predict(self.X_test),
                    target_names=[str(cls) for cls in self.label_encoder.classes_]))

            # Rapport JSON
            rep_json = f"reports/sgd_results_robust_{self.ts}.json"
            with open(rep_json, "w") as f:
                json.dump(self.results, f, indent=2)

            # Matrice de confusion
            plt.figure(figsize=(14, 12))
            sns.heatmap(cm, annot=True, fmt='d', cmap="Blues",
                       xticklabels=self.label_encoder.classes_,
                       yticklabels=self.label_encoder.classes_)
            plt.title(f"Matrice de confusion - SGD Robuste\nAccuracy: {self.results['test_accuracy']:.3f} | F1: {self.results['test_f1']:.3f}")
            plt.ylabel("Vrai")
            plt.xlabel("Pr√©dit")
            fig_path = f"reports/figures/confusion_matrix_sgd_robust_{self.ts}.png"
            plt.tight_layout()
            plt.savefig(fig_path, dpi=220, bbox_inches='tight')
            plt.show()
            plt.close()

            # Courbe d'apprentissage
            train_sizes, tr_scores, val_scores = learning_curve(
                self.model, self.X_train, self.y_train,
                train_sizes=np.linspace(0.1, 1.0, 5), cv=3,
                scoring="f1_weighted", n_jobs=-1
            )

            plt.figure(figsize=(10, 6))
            plt.plot(train_sizes, tr_scores.mean(1), "o-", label="Train", linewidth=2)
            plt.fill_between(train_sizes, tr_scores.mean(1) - tr_scores.std(1),
                           tr_scores.mean(1) + tr_scores.std(1), alpha=0.2)
            plt.plot(train_sizes, val_scores.mean(1), "o-", label="Validation", linewidth=2)
            plt.fill_between(train_sizes, val_scores.mean(1) - val_scores.std(1),
                           val_scores.mean(1) + val_scores.std(1), alpha=0.2)
            plt.xlabel("Taille √©chantillon d'entra√Ænement")
            plt.ylabel("F1-score pond√©r√©")
            plt.title("Courbe d'apprentissage - SGD Robuste")
            plt.legend()
            plt.grid(True, alpha=0.3)
            lc_path = f"reports/figures/learning_curve_sgd_robust_{self.ts}.png"
            plt.tight_layout()
            plt.savefig(lc_path, dpi=220, bbox_inches='tight')
            plt.show()
            plt.close()

            # Graphique des r√©sultats du GridSearch
            if len(self.grid_results) > 1:
                scores = [r['mean_test_score'] for r in self.grid_results]
                plt.figure(figsize=(12, 6))
                plt.plot(range(1, len(scores) + 1), scores, 'b-', alpha=0.7)
                plt.scatter(range(1, len(scores) + 1), scores, c=scores, cmap='viridis', s=30)
                plt.axhline(y=self.best_score, color='r', linestyle='--', label=f'Meilleur: {self.best_score:.4f}')
                plt.xlabel('Combinaison test√©e')
                plt.ylabel('Score F1 pond√©r√© (CV)')
                plt.title('√âvolution des scores - GridSearch par √©tapes')
                plt.legend()
                plt.grid(True, alpha=0.3)
                plt.colorbar(label='Score')
                gs_path = f"reports/figures/gridsearch_progress_robust_{self.ts}.png"
                plt.tight_layout()
                plt.savefig(gs_path, dpi=220, bbox_inches='tight')
                plt.show()
                plt.close()
            else:
                gs_path = None

            elapsed = time.time() - start_time
            print(f"\n‚úÖ Rapports g√©n√©r√©s en {elapsed:.1f}s")

            self.state['reports_done'] = True
            self._save_checkpoint()
            self._print_progress()

            return rep_txt, rep_json, fig_path, lc_path, gs_path

        except Exception as e:
            print(f"‚ùå Erreur rapports: {e}")
            raise

    def cleanup_checkpoint(self):
        if os.path.exists(self.checkpoint_file):
            os.remove(self.checkpoint_file)
            print(f"\nüßπ Checkpoint nettoy√©")

    def get_summary(self):
        print("\n" + "="*60)
        print("üéâ ENTRA√éNEMENT SGD ROBUSTE TERMIN√â")
        print("="*60)

        if self.results:
            print(f"üìä Performance finale:")
            print(f"   ‚Ä¢ Accuracy test: {self.results.get('test_accuracy', 0):.4f}")
            print(f"   ‚Ä¢ F1-score test: {self.results.get('test_f1', 0):.4f}")
            print(f"   ‚Ä¢ Meilleur CV score: {self.best_score:.4f}")

        print(f"\nüîç GridSearch:")
        print(f"   ‚Ä¢ Combinaisons test√©es: {len(self.grid_results)}/{self.total_combinations}")
        print(f"   ‚Ä¢ Taux de completion: {len(self.grid_results)/max(1,self.total_combinations)*100:.1f}%")

        if self.best_params:
            print(f"\nüîß Meilleurs param√®tres:")
            for param, value in self.best_params.items():
                print(f"   ‚Ä¢ {param}: {value}")

        print(f"\nüîÑ Fonctionnalit√©s robustes:")
        print(f"   ‚Ä¢ ‚úÖ GridSearch par √©tapes avec checkpoints")
        print(f"   ‚Ä¢ ‚úÖ Reprise automatique apr√®s d√©connexion")
        print(f"   ‚Ä¢ ‚úÖ Sauvegarde p√©riodique des r√©sultats")
        print(f"   ‚Ä¢ ‚úÖ Progression d√©taill√©e en temps r√©el")

        print(f"\nüìÅ Session: {self.ts}")
        print("="*60)

# ===== Fonction principale robuste =====
def run_robust_training():
    print("üöÄ D√âMARRAGE SGD ROBUSTE (GridSearch par √©tapes)")
    print(f"‚è∞ Heure de d√©but: {datetime.now().strftime('%H:%M:%S')}")
    print("üí° Version r√©sistante aux d√©connexions Google Colab")

    features_file = config["TRAINING"]["SGD"]["DATA_PATH"]
    if not os.path.exists(features_file):
        raise FileNotFoundError(f"‚ùå Fichier des features introuvable: {features_file}")

    start_time = time.time()

    try:
        trainer = SGDTrainerFixedWithCheckpoints(config)

        # Ex√©cution √©tape par √©tape avec checkpoints robustes
        trainer.load_data()
        trainer.preprocess_data()
        trainer.setup_grid_search()
        trainer.optimize_batch()  # GridSearch par lots
        trainer.fit_final()
        cr, cm = trainer.evaluate()
        model_paths = trainer.save()
        report_paths = trainer.reports(cr, cm)

        # Archive
        print("üì¶ Cr√©ation de l'archive...")
        archive = f"sgd_results_robust_{trainer.ts}.zip"
        with zipfile.ZipFile(archive, "w") as z:
            for path in model_paths + (report_paths if report_paths else []):
                if path and os.path.exists(path):
                    z.write(path, os.path.basename(path))

        total_time = time.time() - start_time
        print(f"\n‚è±Ô∏è Temps total: {total_time/60:.1f} minutes")

        trainer.get_summary()

        print(f"üì• T√©l√©chargement: {archive}")
        files.download(archive)
        trainer.cleanup_checkpoint()

        print("\nüéâ SUCC√àS! Entra√Ænement robuste termin√©!")

        return trainer

    except Exception as e:
        elapsed = time.time() - start_time
        print(f"\n‚ùå ERREUR apr√®s {elapsed/60:.1f} minutes: {e}")
        print("üí° Relancez simplement ce code - il reprendra automatiquement!")
        print("üìä Tous les r√©sultats partiels sont sauvegard√©s")
        raise

# ===== Lancement robuste =====
print("‚ö†Ô∏è  LANCEMENT SGD ROBUSTE")
print("üîß GridSearch par √©tapes - R√©sistant aux d√©connexions")
print("üìä Checkpoints automatiques toutes les 5 combinaisons")
print("üîÑ Reprise automatique apr√®s interruption")
print("\n" + "="*60)

trainer = run_robust_training()
