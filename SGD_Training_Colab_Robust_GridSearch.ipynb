# ===== Installation et imports =====
!pip install -q scikit-learn matplotlib seaborn

import numpy as np
import pandas as pd
import sklearn
import os
import json
import pickle
import joblib
import warnings
from datetime import datetime
import time
import zipfile
from google.colab import drive, files
from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import product

warnings.filterwarnings("ignore")
print("Versions -> NumPy:", np.__version__, "| scikit-learn:", sklearn.__version__)
print("ğŸ”§ Version corrigÃ©e avec GridSearch par Ã©tapes")

# ===== Montage Drive et Configuration =====
drive.mount("/content/drive")
PROJECT_PATH = "/content/drive/MyDrive/rakuten-multimodal-classification"  # adapter si besoin
os.chdir(PROJECT_PATH)
print("PWD:", os.getcwd())

for d in ["models", "reports", "reports/figures", "logs", "data/processed", "checkpoints"]:
    os.makedirs(d, exist_ok=True)

config = {
    "TRAINING": {
        "SGD": {
            "DATA_PATH": "data/processed/features_for_dt.csv",
            "PREPROCESSING": {
                "normalize": True,
                "remove_constant_features": True,
                "handle_missing": True,
                "feature_selection": True
            },
            "GRID_SEARCH": {
                "active": True,
                "param_grid": {
                    "loss": ["log_loss", "modified_huber", "hinge"],
                    "alpha": [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],
                    "learning_rate": ["constant", "optimal"],
                    "eta0": [0.001, 0.01, 0.1],
                    "class_weight": [None, "balanced"]
                },
                "cv_folds": 5,
                "scoring": "f1_weighted",
                "n_jobs": -1,
                "batch_size": 10,  # NOUVEAU: traiter par lots de N combinaisons
                "save_interval": 5  # NOUVEAU: sauvegarder toutes les N combinaisons
            },
            "MODEL_PARAMS": {
                "max_iter": 5000,
                "tol": 1e-5,
                "random_state": 42,
                "early_stopping": True,
                "validation_fraction": 0.1,
                "n_iter_no_change": 10
            },
            "EVALUATION": {
                "test_size": 0.2,
                "random_state": 42,
                "stratify": True
            }
        }
    }
}
print("âœ… Configuration amÃ©liorÃ©e chargÃ©e avec GridSearch par Ã©tapes")

# ===== Classe SGDTrainer avec GridSearch Robuste =====
class SGDTrainerFixedWithCheckpoints:
    def __init__(self, cfg):
        self.cfg = cfg
        self.checkpoint_dir = "checkpoints"
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        self.checkpoint_file = self._find_latest_checkpoint() or f"{self.checkpoint_dir}/sgd_checkpoint_fixed_{datetime.now().strftime('%y%m%d-%H%M%S')}.pkl"
        self.ts = self._extract_ts_from_checkpoint(self.checkpoint_file)
        self.model = None
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.feature_selector = VarianceThreshold(threshold=1e-6)
        self.X_train = self.X_test = self.y_train = self.y_test = None
        self.results = {}
        self.best_params = None
        self.pipeline = None
        self.steps = [
            'data_loaded',
            'preprocessing_done',
            'grid_setup_done',
            'optimization_done',
            'training_done',
            'evaluation_done',
            'reports_done'
        ]
        self.state = {step: False for step in self.steps}
        self.step_names = {
            'data_loaded': 'Chargement des donnÃ©es',
            'preprocessing_done': 'Preprocessing',
            'grid_setup_done': 'Setup GridSearch',
            'optimization_done': 'Optimisation GridSearch',
            'training_done': 'EntraÃ®nement final',
            'evaluation_done': 'Ã‰valuation du modÃ¨le',
            'reports_done': 'GÃ©nÃ©ration des rapports'
        }
        self.grid_results = []
        self.best_score = -np.inf
        self.current_batch = 0
        self.total_combinations = 0
        self.param_combinations = []
        print(f"ğŸš€ Init trainer: {self.ts}")
        self._load_checkpoint()
        # Correction : synchronisation des clÃ©s de self.state avec self.steps
        for step in self.steps:
            if step not in self.state:
                self.state[step] = False
        self._print_progress()

    def _find_latest_checkpoint(self):
        """Trouve le dernier checkpoint dans le dossier"""
        files = [f for f in os.listdir(self.checkpoint_dir) if f.startswith('sgd_checkpoint_fixed_') and f.endswith('.pkl')]
        if not files:
            return None
        files = sorted(files, reverse=True)
        return os.path.join(self.checkpoint_dir, files[0])

    def _extract_ts_from_checkpoint(self, checkpoint_file):
        """Extrait le timestamp du nom du checkpoint"""
        try:
            base = os.path.basename(checkpoint_file)
            ts = base.replace('sgd_checkpoint_fixed_', '').replace('.pkl', '')
            return ts
        except:
            return datetime.now().strftime('%y%m%d-%H%M%S')

    def _load_checkpoint(self):
        if os.path.exists(self.checkpoint_file):
            try:
                with open(self.checkpoint_file, 'rb') as f:
                    data = pickle.load(f)
                self.state = data['state']
                self.results = data['results']
                self.best_params = data['best_params']
                self.X_train = data['X_train']
                self.X_test = data['X_test']
                self.y_train = data['y_train']
                self.y_test = data['y_test']
                self.label_encoder = data['label_encoder']
                self.scaler = data.get('scaler', StandardScaler())
                self.feature_selector = data.get('feature_selector', VarianceThreshold(threshold=1e-6))
                self.model = data['model']
                save_time = data.get('timestamp', 'inconnu')
                print(f"ğŸ”„ Checkpoint restaurÃ© (sauvÃ© le: {save_time})")
            except Exception as e:
                print(f"âš ï¸ Erreur checkpoint: {e}")

    def _print_progress(self):
        completed = sum(self.state.values())
        total = len(self.steps)
        percentage = (completed / total) * 100
        print(f"\nğŸ“Š PROGRESSION GLOBALE: {percentage:.1f}% ({completed}/{total})")
        print("=" * 50)
        for step in self.steps:
            status = "âœ…" if self.state[step] else "â³"
            print(f"{status} {self.step_names[step]}")

        # Afficher progression GridSearch si en cours
        if hasattr(self, 'grid_results') and len(self.grid_results) > 0:
            tested = len(self.grid_results)
            total_combs = self.total_combinations if self.total_combinations > 0 else tested
            grid_progress = (tested / total_combs) * 100 if total_combs > 0 else 0
            print(f"ğŸ” GridSearch: {tested}/{total_combs} combinaisons testÃ©es ({grid_progress:.1f}%)")
            if self.best_score > -np.inf:
                print(f"ğŸ† Meilleur score actuel: {self.best_score:.4f}")
        print("=" * 50)

    def _update_progress(self, step_name, substep="", progress=None):
        if progress is not None:
            bar_length = 30
            filled = int(bar_length * progress / 100)
            bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
            print(f"â³ {step_name} {substep}: [{bar}] {progress:.1f}%", end="\r")
        else:
            print(f"â³ {step_name} {substep}")

    def _save_checkpoint(self):
        checkpoint_data = {
            'state': self.state,
            'results': self.results,
            'best_params': self.best_params,
            'best_score': self.best_score,
            'ts': self.ts,
            'X_train': self.X_train,
            'X_test': self.X_test,
            'y_train': self.y_train,
            'y_test': self.y_test,
            'label_encoder': self.label_encoder,
            'scaler': self.scaler,
            'feature_selector': self.feature_selector,
            'model': self.model,
            'grid_results': self.grid_results,
            'current_batch': self.current_batch,
            'total_combinations': self.total_combinations,
            'param_combinations': self.param_combinations,
            'timestamp': datetime.now().isoformat()
        }
        with open(self.checkpoint_file, 'wb') as f:
            pickle.dump(checkpoint_data, f)
        file_size = os.path.getsize(self.checkpoint_file) / (1024 * 1024)
        print(f"\nğŸ’¾ Checkpoint sauvÃ© ({file_size:.1f} MB)")

    def load_data(self):
        if self.state['data_loaded']:
            print("âœ… DonnÃ©es dÃ©jÃ  chargÃ©es")
            return
        print(f"\nğŸ¯ Ã‰TAPE 1/7: {self.step_names['data_loaded']}")
        start_time = time.time()
        path = self.cfg["TRAINING"]["SGD"]["DATA_PATH"]
        self._update_progress("Chargement", "Lecture du CSV", 20)
        df = pd.read_csv(path)
        self._update_progress("Chargement", "Identification target", 40)

        if "label" in df.columns:
            target = "label"
        else:
            target_candidates = [col for col in df.columns if df[col].nunique() == 27]
            if target_candidates:
                target = target_candidates[0]
            else:
                raise ValueError("Impossible de trouver la colonne target avec 27 classes")

        self._update_progress("Chargement", "SÃ©paration X/y", 60)
        X = df.drop(columns=[target])
        y = df[target]

        print(f"\nğŸ“Š Diagnostic initial:")
        print(f"   Forme: {X.shape}")
        print(f"   Classes: {y.nunique()}")
        print(f"   Distribution: min={y.value_counts().min()}, max={y.value_counts().max()}")
        print(f"   Ratio dÃ©sÃ©quilibre: {y.value_counts().max() / y.value_counts().min():.1f}:1")

        self._update_progress("Chargement", "Encodage labels", 80)
        y_enc = self.label_encoder.fit_transform(y)

        self._update_progress("Chargement", "Split train/test", 90)
        ev = self.cfg["TRAINING"]["SGD"]["EVALUATION"]
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y_enc,
            test_size=ev["test_size"],
            random_state=ev["random_state"],
            stratify=y_enc if ev["stratify"] else None
        )

        elapsed = time.time() - start_time
        print(f"\nâœ… DonnÃ©es chargÃ©es en {elapsed:.1f}s")
        print(f"   Train: {self.X_train.shape}, Test: {self.X_test.shape}")
        self.state['data_loaded'] = True
        self._save_checkpoint()
        self._print_progress()

    def preprocess_data(self):
        if self.state['preprocessing_done']:
            print("âœ… Preprocessing dÃ©jÃ  effectuÃ©")
            return
        print(f"\nğŸ¯ Ã‰TAPE 2/7: {self.step_names['preprocessing_done']}")
        start_time = time.time()

        # Suppression features constantes
        self._update_progress("Preprocessing", "Suppression features constantes", 20)
        constant_features = [col for col in self.X_train.columns if self.X_train[col].nunique() <= 1]
        if constant_features:
            print(f"\nğŸ§¹ Suppression de {len(constant_features)} features constantes")
            self.X_train = self.X_train.drop(columns=constant_features)
            self.X_test = self.X_test.drop(columns=constant_features)

        # SÃ©lection par variance
        self._update_progress("Preprocessing", "SÃ©lection par variance", 40)
        X_train_selected = self.feature_selector.fit_transform(self.X_train)
        X_test_selected = self.feature_selector.transform(self.X_test)
        n_features_removed = self.X_train.shape[1] - X_train_selected.shape[1]
        if n_features_removed > 0:
            print(f"\nğŸ§¹ Suppression de {n_features_removed} features Ã  faible variance")

        # Normalisation StandardScaler (CRITIQUE)
        self._update_progress("Preprocessing", "Normalisation StandardScaler", 70)
        X_train_scaled = self.scaler.fit_transform(X_train_selected)
        X_test_scaled = self.scaler.transform(X_test_selected)

        mean_check = np.abs(X_train_scaled.mean(axis=0)).max()
        std_check = X_train_scaled.std(axis=0).max()
        print(f"\nâœ… Normalisation vÃ©rifiÃ©e:")
        print(f"   Moyenne max: {mean_check:.6f} (doit Ãªtre ~0)")
        print(f"   Std max: {std_check:.6f} (doit Ãªtre ~1)")

        self.X_train = X_train_scaled
        self.X_test = X_test_scaled

        elapsed = time.time() - start_time
        print(f"\nâœ… Preprocessing terminÃ© en {elapsed:.1f}s")
        print(f"   Features finales: {self.X_train.shape[1]}")

        self.state['preprocessing_done'] = True
        self._save_checkpoint()
        self._print_progress()

    def setup_grid_search(self):
        """PrÃ©pare toutes les combinaisons de paramÃ¨tres pour le GridSearch par Ã©tapes"""
        if self.state['grid_setup_done']:
            print("âœ… Setup GridSearch dÃ©jÃ  effectuÃ©")
            return

        print(f"\nğŸ¯ Ã‰TAPE 3/7: {self.step_names['grid_setup_done']}")

        gs_cfg = self.cfg["TRAINING"]["SGD"]["GRID_SEARCH"]
        if not gs_cfg["active"]:
            print("â­ï¸ GridSearch dÃ©sactivÃ©")
            self.state['grid_setup_done'] = True
            self.state['optimization_done'] = True
            self._save_checkpoint()
            return

        # GÃ©nÃ©rer toutes les combinaisons
        param_names = list(gs_cfg["param_grid"].keys())
        param_values = list(gs_cfg["param_grid"].values())

        self.param_combinations = []
        for combination in product(*param_values):
            param_dict = dict(zip(param_names, combination))
            self.param_combinations.append(param_dict)

        self.total_combinations = len(self.param_combinations)
        batch_size = gs_cfg.get("batch_size", 10)

        print(f"ğŸ” GridSearch Setup:")
        print(f"   Total combinaisons: {self.total_combinations}")
        print(f"   Taille des lots: {batch_size}")
        print(f"   Nombre de lots: {(self.total_combinations + batch_size - 1) // batch_size}")
        print(f"   CV folds: {gs_cfg['cv_folds']}")

        # Estimer le temps par combinaison (plus conservateur pour Colab)
        estimated_time_per_combo = 30  # secondes
        total_estimated_minutes = (self.total_combinations * estimated_time_per_combo) / 60
        print(f"   Temps estimÃ© total: ~{total_estimated_minutes:.1f} minutes")
        print(f"   Temps par lot: ~{(batch_size * estimated_time_per_combo)/60:.1f} minutes")

        self.state['grid_setup_done'] = True
        self._save_checkpoint()
        self._print_progress()

    def optimize_batch(self):
        """Optimise le modÃ¨le par lots de combinaisons avec checkpoints frÃ©quents"""
        if self.state['optimization_done']:
            print("âœ… Optimisation dÃ©jÃ  effectuÃ©e")
            return

        if not self.state['grid_setup_done']:
            self.setup_grid_search()

        print(f"\nğŸ¯ Ã‰TAPE 4/7: {self.step_names['optimization_done']}")

        gs_cfg = self.cfg["TRAINING"]["SGD"]["GRID_SEARCH"]
        batch_size = gs_cfg.get("batch_size", 10)
        save_interval = gs_cfg.get("save_interval", 5)

        # Reprendre oÃ¹ on s'Ã©tait arrÃªtÃ©
        start_idx = len(self.grid_results)
        remaining_combinations = self.param_combinations[start_idx:]

        if len(remaining_combinations) == 0:
            print("âœ… Toutes les combinaisons ont dÃ©jÃ  Ã©tÃ© testÃ©es")
            self.state['optimization_done'] = True
            self._save_checkpoint()
            return

        print(f"ğŸ”„ Reprise GridSearch: {start_idx}/{self.total_combinations} combinaisons dÃ©jÃ  testÃ©es")
        print(f"ğŸ“Š Reste Ã  tester: {len(remaining_combinations)} combinaisons")

        base_params = self.cfg["TRAINING"]["SGD"]["MODEL_PARAMS"].copy()

        start_time = time.time()
        last_save_time = start_time

        for i, params in enumerate(remaining_combinations):
            current_idx = start_idx + i
            print(f"\nğŸ” Test {current_idx + 1}/{self.total_combinations}: {params}")

            try:
                # CrÃ©er le modÃ¨le avec les paramÃ¨tres actuels
                model_params = base_params.copy()
                model_params.update(params)

                clf = SGDClassifier(**model_params)

                # Cross-validation
                cv_start = time.time()
                scores = cross_val_score(
                    clf, self.X_train, self.y_train,
                    cv=gs_cfg["cv_folds"],
                    scoring=gs_cfg["scoring"],
                    n_jobs=1  # Ã‰viter les problÃ¨mes de mÃ©moire sur Colab
                )
                cv_time = time.time() - cv_start

                mean_score = scores.mean()
                std_score = scores.std()

                # Enregistrer le rÃ©sultat
                result = {
                    'params': params.copy(),
                    'mean_test_score': mean_score,
                    'std_test_score': std_score,
                    'individual_scores': scores.tolist(),
                    'cv_time': cv_time,
                    'timestamp': datetime.now().isoformat()
                }

                self.grid_results.append(result)

                # Mettre Ã  jour le meilleur score
                if mean_score > self.best_score:
                    self.best_score = mean_score
                    self.best_params = params.copy()
                    print(f"ğŸ† NOUVEAU MEILLEUR SCORE: {mean_score:.4f} (Â±{std_score:.4f})")
                    print(f"ğŸ”§ ParamÃ¨tres: {params}")
                else:
                    print(f"ğŸ“Š Score: {mean_score:.4f} (Â±{std_score:.4f}) - temps: {cv_time:.1f}s")

                # Sauvegarde pÃ©riodique
                if (i + 1) % save_interval == 0 or time.time() - last_save_time > 300:  # Toutes les 5 min minimum
                    self._save_checkpoint()
                    last_save_time = time.time()

                    elapsed = time.time() - start_time
                    remaining = len(remaining_combinations) - i - 1
                    if remaining > 0:
                        eta = (elapsed / (i + 1)) * remaining
                        print(f"â±ï¸ Progression: {i+1}/{len(remaining_combinations)} - ETA: {eta/60:.1f} min")

                # Pause pour Ã©viter la surcharge
                time.sleep(1)

            except Exception as e:
                print(f"âŒ Erreur avec {params}: {e}")
                # Continuer avec les autres combinaisons
                continue

        # Sauvegarde finale
        self.state['optimization_done'] = True
        self._save_checkpoint()

        elapsed = time.time() - start_time
        print(f"\nâœ… GridSearch terminÃ© en {elapsed/60:.1f} minutes")
        print(f"ğŸ† Meilleur score: {self.best_score:.4f}")
        print(f"ğŸ”§ Meilleurs paramÃ¨tres: {self.best_params}")

        # Afficher le top 5
        sorted_results = sorted(self.grid_results, key=lambda x: x['mean_test_score'], reverse=True)
        print(f"\nğŸ“Š TOP 5 COMBINAISONS:")
        for i, result in enumerate(sorted_results[:5]):
            print(f"   {i+1}. Score: {result['mean_test_score']:.4f} - {result['params']}")

        self._print_progress()

    def fit_final(self):
        if self.state['training_done']:
            print("âœ… EntraÃ®nement final dÃ©jÃ  effectuÃ©")
            return
        print(f"\nğŸ¯ Ã‰TAPE 5/7: {self.step_names['training_done']}")
        start_time = time.time()

        if self.best_params is None:
            print("âš ï¸ Aucuns meilleurs paramÃ¨tres trouvÃ©s, utilisation des paramÃ¨tres par dÃ©faut")
            params = self.cfg["TRAINING"]["SGD"]["MODEL_PARAMS"].copy()
        else:
            params = self.cfg["TRAINING"]["SGD"]["MODEL_PARAMS"].copy()
            params.update(self.best_params)

        print(f"ğŸ”§ ParamÃ¨tres finaux: {params}")

        self.model = Pipeline([
            ('sgd', SGDClassifier(**params))
        ])

        try:
            self._update_progress("EntraÃ®nement", "Sur donnÃ©es normalisÃ©es", 50)
            self.model.fit(self.X_train, self.y_train)

            sgd_model = self.model.named_steps['sgd']
            n_iter = getattr(sgd_model, 'n_iter_', 'N/A')

            elapsed = time.time() - start_time
            print(f"\nâœ… EntraÃ®nement terminÃ© en {elapsed:.1f}s")
            print(f"ğŸ“ˆ Nombre d'itÃ©rations: {n_iter}")

            self.state['training_done'] = True
            self._save_checkpoint()
            self._print_progress()

        except Exception as e:
            print(f"âŒ Erreur entraÃ®nement: {e}")
            raise

    def evaluate(self):
        if self.state['evaluation_done']:
            print("âœ… Ã‰valuation dÃ©jÃ  effectuÃ©e")
            return self.results.get("classification_report"), self.results.get("confusion_matrix")

        print(f"\nğŸ¯ Ã‰TAPE 6/7: {self.step_names['evaluation_done']}")
        start_time = time.time()

        try:
            self._update_progress("Ã‰valuation", "PrÃ©dictions", 50)
            ytr_pred = self.model.predict(self.X_train)
            yte_pred = self.model.predict(self.X_test)

            self.results.update({
                "train_accuracy": accuracy_score(self.y_train, ytr_pred),
                "test_accuracy": accuracy_score(self.y_test, yte_pred),
                "train_f1": f1_score(self.y_train, ytr_pred, average="weighted"),
                "test_f1": f1_score(self.y_test, yte_pred, average="weighted"),
                "best_cv_score": self.best_score,
                "grid_search_results": self.grid_results[-10:] if len(self.grid_results) > 10 else self.grid_results
            })

            cr = classification_report(self.y_test, yte_pred,
                                     target_names=[str(cls) for cls in self.label_encoder.classes_],
                                     output_dict=True)
            cm = confusion_matrix(self.y_test, yte_pred)

            self.results["classification_report"] = cr
            self.results["confusion_matrix"] = cm.tolist()
            self.results["class_names"] = [str(cls) for cls in self.label_encoder.classes_]

            elapsed = time.time() - start_time
            print(f"\nâœ… Ã‰valuation terminÃ©e en {elapsed:.1f}s")
            print(f"ğŸ“Š RÃ‰SULTATS FINAUX:")
            print(f"   Accuracy: {self.results['test_accuracy']:.4f}")
            print(f"   F1-score: {self.results['test_f1']:.4f}")
            print(f"   Meilleur CV score: {self.best_score:.4f}")

            unique_preds = len(np.unique(yte_pred))
            print(f"   Classes prÃ©dites: {unique_preds}/27")

            self.state['evaluation_done'] = True
            self._save_checkpoint()
            self._print_progress()
            return cr, cm

        except Exception as e:
            print(f"âŒ Erreur Ã©valuation: {e}")
            raise

    def save(self):
        print("ğŸ’¾ Sauvegarde des modÃ¨les...")
        mp = f"models/sgd_classifier_robust_{self.ts}.pkl"
        ep = f"models/sgd_label_encoder_robust_{self.ts}.pkl"
        sp = f"models/sgd_scaler_robust_{self.ts}.pkl"
        fp = f"models/sgd_feature_selector_robust_{self.ts}.pkl"
        gp = f"models/sgd_grid_results_robust_{self.ts}.json"

        joblib.dump(self.model, mp)
        joblib.dump(self.label_encoder, ep)
        joblib.dump(self.scaler, sp)
        joblib.dump(self.feature_selector, fp)

        # Sauvegarder les rÃ©sultats du GridSearch
        with open(gp, 'w') as f:
            json.dump({
                'best_params': self.best_params,
                'best_score': self.best_score,
                'all_results': self.grid_results,
                'total_combinations_tested': len(self.grid_results),
                'timestamp': datetime.now().isoformat()
            }, f, indent=2)

        return mp, ep, sp, fp, gp

    def reports(self, cr, cm):
        if self.state['reports_done']:
            print("âœ… Rapports dÃ©jÃ  gÃ©nÃ©rÃ©s")
            return

        print(f"\nğŸ¯ Ã‰TAPE 7/7: {self.step_names['reports_done']}")
        start_time = time.time()

        try:
            # Rapport texte
            rep_txt = f"reports/sgd_classification_report_robust_{self.ts}.txt"
            with open(rep_txt, "w") as f:
                f.write("=== RAPPORT SGD ROBUSTE (GridSearch par Ã©tapes) ===\n")
                f.write(f"Timestamp: {self.ts}\n")
                f.write(f"Features finales: {self.X_train.shape[1]}\n")
                f.write(f"Combinaisons testÃ©es: {len(self.grid_results)}/{self.total_combinations}\n\n")
                f.write("MÃ‰TRIQUES PRINCIPALES:\n")
                f.write(json.dumps({
                    "train_accuracy": self.results["train_accuracy"],
                    "test_accuracy": self.results["test_accuracy"],
                    "train_f1": self.results["train_f1"],
                    "test_f1": self.results["test_f1"],
                    "best_params": self.best_params,
                    "best_cv_score": self.best_score
                }, indent=2))
                f.write("\n\nRAPPORT DÃ‰TAILLÃ‰:\n")
                f.write(classification_report(
                    self.y_test, self.model.predict(self.X_test),
                    target_names=[str(cls) for cls in self.label_encoder.classes_]))

            # Rapport JSON
            rep_json = f"reports/sgd_results_robust_{self.ts}.json"
            with open(rep_json, "w") as f:
                json.dump(self.results, f, indent=2)

            # Matrice de confusion
            plt.figure(figsize=(14, 12))
            sns.heatmap(cm, annot=True, fmt='d', cmap="Blues",
                       xticklabels=self.label_encoder.classes_,
                       yticklabels=self.label_encoder.classes_)
            plt.title(f"Matrice de confusion - SGD Robuste\nAccuracy: {self.results['test_accuracy']:.3f} | F1: {self.results['test_f1']:.3f}")
            plt.ylabel("Vrai")
            plt.xlabel("PrÃ©dit")
            fig_path = f"reports/figures/confusion_matrix_sgd_robust_{self.ts}.png"
            plt.tight_layout()
            plt.savefig(fig_path, dpi=220, bbox_inches='tight')
            plt.show()
            plt.close()

            # Courbe d'apprentissage
            train_sizes, tr_scores, val_scores = learning_curve(
                self.model, self.X_train, self.y_train,
                train_sizes=np.linspace(0.1, 1.0, 5), cv=3,
                scoring="f1_weighted", n_jobs=-1
            )

            plt.figure(figsize=(10, 6))
            plt.plot(train_sizes, tr_scores.mean(1), "o-", label="Train", linewidth=2)
            plt.fill_between(train_sizes, tr_scores.mean(1) - tr_scores.std(1),
                           tr_scores.mean(1) + tr_scores.std(1), alpha=0.2)
            plt.plot(train_sizes, val_scores.mean(1), "o-", label="Validation", linewidth=2)
            plt.fill_between(train_sizes, val_scores.mean(1) - val_scores.std(1),
                           val_scores.mean(1) + val_scores.std(1), alpha=0.2)
            plt.xlabel("Taille Ã©chantillon d'entraÃ®nement")
            plt.ylabel("F1-score pondÃ©rÃ©")
            plt.title("Courbe d'apprentissage - SGD Robuste")
            plt.legend()
            plt.grid(True, alpha=0.3)
            lc_path = f"reports/figures/learning_curve_sgd_robust_{self.ts}.png"
            plt.tight_layout()
            plt.savefig(lc_path, dpi=220, bbox_inches='tight')
            plt.show()
            plt.close()

            # Graphique des rÃ©sultats du GridSearch
            if len(self.grid_results) > 1:
                scores = [r['mean_test_score'] for r in self.grid_results]
                plt.figure(figsize=(12, 6))
                plt.plot(range(1, len(scores) + 1), scores, 'b-', alpha=0.7)
                plt.scatter(range(1, len(scores) + 1), scores, c=scores, cmap='viridis', s=30)
                plt.axhline(y=self.best_score, color='r', linestyle='--', label=f'Meilleur: {self.best_score:.4f}')
                plt.xlabel('Combinaison testÃ©e')
                plt.ylabel('Score F1 pondÃ©rÃ© (CV)')
                plt.title('Ã‰volution des scores - GridSearch par Ã©tapes')
                plt.legend()
                plt.grid(True, alpha=0.3)
                plt.colorbar(label='Score')
                gs_path = f"reports/figures/gridsearch_progress_robust_{self.ts}.png"
                plt.tight_layout()
                plt.savefig(gs_path, dpi=220, bbox_inches='tight')
                plt.show()
                plt.close()
            else:
                gs_path = None

            elapsed = time.time() - start_time
            print(f"\nâœ… Rapports gÃ©nÃ©rÃ©s en {elapsed:.1f}s")

            self.state['reports_done'] = True
            self._save_checkpoint()
            self._print_progress()

            return rep_txt, rep_json, fig_path, lc_path, gs_path

        except Exception as e:
            print(f"âŒ Erreur rapports: {e}")
            raise

    def cleanup_checkpoint(self):
        if os.path.exists(self.checkpoint_file):
            os.remove(self.checkpoint_file)
            print(f"\nğŸ§¹ Checkpoint nettoyÃ©")

    def get_summary(self):
        print("\n" + "="*60)
        print("ğŸ‰ ENTRAÃNEMENT SGD ROBUSTE TERMINÃ‰")
        print("="*60)

        if self.results:
            print(f"ğŸ“Š Performance finale:")
            print(f"   â€¢ Accuracy test: {self.results.get('test_accuracy', 0):.4f}")
            print(f"   â€¢ F1-score test: {self.results.get('test_f1', 0):.4f}")
            print(f"   â€¢ Meilleur CV score: {self.best_score:.4f}")

        print(f"\nğŸ” GridSearch:")
        print(f"   â€¢ Combinaisons testÃ©es: {len(self.grid_results)}/{self.total_combinations}")
        print(f"   â€¢ Taux de completion: {len(self.grid_results)/max(1,self.total_combinations)*100:.1f}%")

        if self.best_params:
            print(f"\nğŸ”§ Meilleurs paramÃ¨tres:")
            for param, value in self.best_params.items():
                print(f"   â€¢ {param}: {value}")

        print(f"\nğŸ”„ FonctionnalitÃ©s robustes:")
        print(f"   â€¢ âœ… GridSearch par Ã©tapes avec checkpoints")
        print(f"   â€¢ âœ… Reprise automatique aprÃ¨s dÃ©connexion")
        print(f"   â€¢ âœ… Sauvegarde pÃ©riodique des rÃ©sultats")
        print(f"   â€¢ âœ… Progression dÃ©taillÃ©e en temps rÃ©el")

        print(f"\nğŸ“ Session: {self.ts}")
        print("="*60)

# ===== Fonction principale robuste =====
def run_robust_training():
    print("ğŸš€ DÃ‰MARRAGE SGD ROBUSTE (GridSearch par Ã©tapes)")
    print(f"â° Heure de dÃ©but: {datetime.now().strftime('%H:%M:%S')}")
    print("ğŸ’¡ Version rÃ©sistante aux dÃ©connexions Google Colab")

    features_file = config["TRAINING"]["SGD"]["DATA_PATH"]
    if not os.path.exists(features_file):
        raise FileNotFoundError(f"âŒ Fichier des features introuvable: {features_file}")

    start_time = time.time()

    try:
        trainer = SGDTrainerFixedWithCheckpoints(config)

        # ExÃ©cution Ã©tape par Ã©tape avec checkpoints robustes
        trainer.load_data()
        trainer.preprocess_data()
        trainer.setup_grid_search()
        trainer.optimize_batch()  # GridSearch par lots
        trainer.fit_final()
        cr, cm = trainer.evaluate()
        model_paths = trainer.save()
        report_paths = trainer.reports(cr, cm)

        # Archive
        print("ğŸ“¦ CrÃ©ation de l'archive...")
        archive = f"sgd_results_robust_{trainer.ts}.zip"
        with zipfile.ZipFile(archive, "w") as z:
            for path in model_paths + (report_paths if report_paths else []):
                if path and os.path.exists(path):
                    z.write(path, os.path.basename(path))

        total_time = time.time() - start_time
        print(f"\nâ±ï¸ Temps total: {total_time/60:.1f} minutes")

        trainer.get_summary()

        print(f"ğŸ“¥ TÃ©lÃ©chargement: {archive}")
        files.download(archive)
        trainer.cleanup_checkpoint()

        print("\nğŸ‰ SUCCÃˆS! EntraÃ®nement robuste terminÃ©!")

        return trainer

    except Exception as e:
        elapsed = time.time() - start_time
        print(f"\nâŒ ERREUR aprÃ¨s {elapsed/60:.1f} minutes: {e}")
        print("ğŸ’¡ Relancez simplement ce code - il reprendra automatiquement!")
        print("ğŸ“Š Tous les rÃ©sultats partiels sont sauvegardÃ©s")
        raise

# ===== Lancement robuste =====
print("âš ï¸  LANCEMENT SGD ROBUSTE")
print("ğŸ”§ GridSearch par Ã©tapes - RÃ©sistant aux dÃ©connexions")
print("ğŸ“Š Checkpoints automatiques toutes les 5 combinaisons")
print("ğŸ”„ Reprise automatique aprÃ¨s interruption")
print("\n" + "="*60)

trainer = run_robust_training()
