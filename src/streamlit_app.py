import streamlit as st
import pandas as pd
import json
from pathlib import Path
from PIL import Image
from models.EfficientNet.predict import predict_efficientNet
import os

# Configuration
st.set_page_config(
    page_title="Rakuten Classification",
    page_icon="üõçÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
.main-header {font-size:2.5rem;font-weight:bold;color:#FF6B6B;text-align:center;padding:1rem;}
.metric-box {background:#f0f2f6;border-radius:10px;padding:1rem;margin:0.5rem 0;}
</style>
""", unsafe_allow_html=True)

# Helper functions
@st.cache_data
def load_metrics(model_name):
    """Charge les m√©triques d'un mod√®le"""
    try:
        path = Path(f"models/{model_name}/metrics/metrics_summary.json")
        if path.exists():
            with open(path) as f:
                return json.load(f)
    except Exception as e:
        st.error(f"Erreur: {e}")
    return None

@st.cache_data
def load_image(path):
    """Charge une image"""
    if Path(path).exists():
        return Image.open(path)
    return None

# Navigation sidebar
st.sidebar.title("üìã Navigation")
page = st.sidebar.radio(
    "Aller √†:",
    [
        "Introduction",
        "Preprocessing",
        "Mod√©lisation",
        "R√©sultats",
        "Demo",
        "Ouverture",
        "Conclusion"
    ],
    format_func=lambda x: {
        "Introduction": "üè† Introduction",
        "Preprocessing": "üîß Preprocessing",
        "Mod√©lisation": "ü§ñ Mod√©lisation",
        "R√©sultats": "üìä R√©sultats",
        "Demo": "üéÆ D√©mo Live",
        "Ouverture": "üîÆ Ouverture",
        "Conclusion": "‚úÖ Conclusion"
    }.get(x, x)
)

# PAGE 1: INTRODUCTION
if page == "Introduction":
    st.markdown('<div class="main-header">üõçÔ∏è Classification Multimodale Rakuten</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # M√©triques cl√©s
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="Classes", value="27", delta="Cat√©gories produits")
    with col2:
        st.metric(label="√âchantillons", value="84 916", delta="Total dataset")
    with col3:
        st.metric(label="Features Max", value="16 192", delta="Dimensions SGDC")
    
    st.markdown("### üéØ Objectif du Projet")
    st.write("""
    D√©velopper un syst√®me de classification automatique capable de cat√©goriser 
    les produits Rakuten en utilisant √† la fois les descriptions textuelles et les images.
    """)
    
    st.markdown("### üîç Probl√©matique")
    col1, col2 = st.columns(2)
    with col1:
        st.info("""
        **Challenge**
        - 27 cat√©gories diff√©rentes
        - Donn√©es multimodales (texte + images)
        - Vocabulaire riche et vari√©
        - Classes d√©s√©quilibr√©es (ratio 1:50)
        """)
    with col2:
        st.success("""
        **Notre Approche**
        - TF-IDF pour le texte (8K features)
        - Histogrammes RGB pour images (192 features)
        - Mod√®les ML classiques (SGDC, DecisionTree, RF)
        - Optimisation hyperparam√®tres
        """)
    
    st.markdown("### üìä Dataset Rakuten")
    data_overview = {
        "M√©trique": ["Total produits", "Train (80%)", "Test (20%)", "Classes", "D√©s√©quilibre max"],
        "Valeur": ["84 916", "67 933", "16 983", "27", "~1:50"]
    }
    st.table(pd.DataFrame(data_overview))
    
    st.markdown("### üë• Contexte")
    st.write("**Projet DataScientest** - Formation Data Scientist - Janvier 2025")

# PAGE 2: PREPROCESSING
elif page == "Preprocessing":
    st.markdown('<div class="main-header">üîß Pipeline de Preprocessing</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    st.markdown("### üìù Preprocessing Textuel")
    
    with st.expander("‚öôÔ∏è √âtapes d√©taill√©es", expanded=True):
        st.markdown("""
        **1. Nettoyage**
        - Conversion en minuscules
        - Suppression de la ponctuation
        - Suppression des stopwords fran√ßais
        
        **2. Vectorisation TF-IDF**
        - Unigrammes + bigrammes (1-2 mots)
        - max_features: 8000 (SGDC) / 5000 (DecisionTree)
        - min_df: 2 (minimum 2 documents)
        - max_df: 0.95 (maximum 95% documents)
        
        **3. Normalisation**
        - Normalisation L2 des vecteurs TF-IDF
        """)
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**üìÑ Avant nettoyage**")
        st.code("""
Produit: Livre Harry Potter - √âtat NEUF!!!
Prix: 15,99‚Ç¨ (Livraison GRATUITE)
Description: Roman fantasy pour jeunes...
        """, language="text")
    
    with col2:
        st.markdown("**‚ú® Apr√®s nettoyage**")
        st.code("""
livre harry potter √©tat neuf
prix livraison gratuite  
roman fantasy jeunes
        """, language="text")
    
    st.markdown("### üñºÔ∏è Preprocessing Images")
    
    with st.expander("‚öôÔ∏è Extraction features visuelles", expanded=True):
        st.markdown("""
        **1. Redimensionnement**
        - Resize uniforme: 128√ó128 pixels
        
        **2. Histogrammes couleur RGB**
        - 64 bins par canal (R, G, B)
        - Total: 192 features num√©riques
        
        **3. Normalisation**
        - Min-Max scaling sur [0, 1]
        """)
    
    st.markdown("### üîó Features Finales par Mod√®le")
    
    features_comparison = {
        "Mod√®le": ["SGDC", "DecisionTree", "Random Forest"],
        "Features Texte": ["16 000", "10 000", "10 000"],
        "Features Image": ["192", "192", "192"],
        "Total Features": ["16 192", "10 192", "10 192"],
        "√âchantillons": ["10 000", "5 000", "5 000"]
    }
    st.dataframe(pd.DataFrame(features_comparison), width='stretch')
    
    st.info("üí° **Note**: Le texte repr√©sente >98% des features. C'est normal pour un site e-commerce o√π les descriptions sont tr√®s informatives.")

# PAGE 3: MOD√âLISATION  
elif page == "Mod√©lisation":
    st.markdown('<div class="main-header">ü§ñ Mod√©lisation</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìà SGDClassifier", "üå≥ DecisionTree", "üå≤ Random Forest", "üß† Deep Learning", "EfficientNet"])
    
    # TAB 1: SGDC
    with tab1:
        st.markdown("## üìà SGDClassifier")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("#### Principe de fonctionnement")
            st.write("""
            Mod√®le **lin√©aire** qui apprend progressivement en analysant les exemples  
            un par un (ou par mini-batches). Il trace 27 hyperplans dans un espace  
            √† 16 192 dimensions pour s√©parer chaque cat√©gorie de produit.
            """)
            
            st.markdown("#### Hyperparam√®tres")
            with st.expander("Voir la configuration", expanded=True):
                st.code("""
loss='log_loss'          # Fonction de perte logistique
penalty='elasticnet'     # R√©gularisation L1 + L2
alpha=0.00005           # Faible p√©nalisation
l1_ratio=0.15           # Mix 15% L1, 85% L2
max_iter=150            # 150 passages sur donn√©es
learning_rate='optimal' # Taux adaptatif
early_stopping=True     # Arr√™t si stagnation
                """, language="python")
        
        with col2:
            metrics_sgdc = load_metrics("SGDCModel")
            if metrics_sgdc:
                st.metric("Accuracy", f"{metrics_sgdc.get('accuracy', 0)*100:.1f}%", delta="‚≠ê Excellent")
                st.metric("F1-Score", f"{metrics_sgdc.get('f1_weighted', 0)*100:.1f}%")
                st.metric("Precision", f"{metrics_sgdc.get('precision_weighted', 0)*100:.1f}%")
                st.metric("Recall", f"{metrics_sgdc.get('recall_weighted', 0)*100:.1f}%")
        
        st.markdown("#### Avantages & Inconv√©nients")
        col1, col2 = st.columns(2)
        
        with col1:
            st.success("""
            **‚úÖ Avantages**
            - Performance excellente (75.4%)
            - Scalable (millions d'exemples possibles)
            - Rapide (4 minutes training)
            - Pas de surapprentissage
            - Exploite haute dimensionnalit√©
            """)
        
        with col2:
            st.warning("""
            **‚ö†Ô∏è Inconv√©nients**
            - Interpr√©tabilit√© limit√©e
            - Hypoth√®se de lin√©arit√©
            - Features images sous-exploit√©es
            - N√©cessite preprocessing soign√©
            """)
    
    # TAB 2: DecisionTree
    with tab2:
        st.markdown("## üå≥ DecisionTree")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("#### Principe de fonctionnement")
            st.write("""
            Arbre de d√©cisions qui pose des questions s√©quentielles sur les features.
            Comme un jeu de 20 questions pour deviner la cat√©gorie du produit.
            """)
            
            st.markdown("#### Hyperparam√®tres")
            with st.expander("Voir la configuration", expanded=True):
                st.code("""
criterion='gini'         # Mesure d'impuret√©
max_depth=20            # Profondeur max 20 niveaux
min_samples_split=30    # Min 30 pour diviser
min_samples_leaf=15     # Min 15 par feuille
max_features=0.7        # 70% features par split
max_leaf_nodes=500      # Max 500 feuilles
ccp_alpha=0.001         # Pruning post-construction
                """, language="python")
        
        with col2:
            metrics_dt = load_metrics("DecisionTreeModel")
            if metrics_dt:
                st.metric("Accuracy", f"{metrics_dt.get('accuracy', 0)*100:.1f}%")
                st.metric("F1-Score", f"{metrics_dt.get('f1_weighted', 0)*100:.1f}%")
                st.metric("Overfitting Gap", f"{metrics_dt.get('overfitting_gap', 0)*100:.1f}%", delta="‚úÖ Excellent")
        
        st.markdown("#### Avantages & Inconv√©nients")
        col1, col2 = st.columns(2)
        
        with col1:
            st.success("""
            **‚úÖ Avantages**
            - Interpr√©tabilit√© maximale ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
            - R√®gles IF/THEN explicites
            - Ultra-rapide (5 secondes)
            - Pas d'overfitting (2.5% gap)
            - Visualisation possible
            """)
        
        with col2:
            st.warning("""
            **‚ö†Ô∏è Inconv√©nients**
            - Performance faible (40.9%)
            - Un seul arbre insuffisant
            - 5 classes jamais pr√©dites
            - Haute dimensionnalit√© toxique
            """)
    
    # TAB 3: Random Forest
    with tab3:
        st.markdown("## üå≤ Random Forest")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("#### Principe de fonctionnement")
            st.write("""
            Ensemble de 50 arbres de d√©cision qui votent pour la pr√©diction finale.
            Am√©liore la performance en moyennant les d√©cisions de multiples arbres.
            """)
            
            st.markdown("#### Hyperparam√®tres")
            with st.expander("Voir la configuration", expanded=True):
                st.code("""
n_estimators=50         # 50 arbres
max_depth=20            # Profondeur max
min_samples_split=30    
min_samples_leaf=15
max_features=0.7
                """, language="python")
        
        with col2:
            metrics_rf = load_metrics("RandomForest")
            if metrics_rf:
                st.metric("Accuracy", f"{metrics_rf.get('accuracy', 0)*100:.1f}%")
                st.metric("F1-Score", f"{metrics_rf.get('f1_weighted', 0)*100:.1f}%")
                st.metric("Overfitting Gap", f"{metrics_rf.get('overfitting_gap', 0)*100:.1f}%")
        
        st.markdown("#### Comparaison des 3 Mod√®les")
        comparison = {
            "Mod√®le": ["DecisionTree", "Random Forest", "SGDClassifier"],
            "Accuracy": ["40.9%", "50.8%", "75.4%"],
            "Temps Training": ["5 sec", "30 sec", "4 min"],
            "Interpr√©tabilit√©": ["‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê"],
            "Scalabilit√©": ["‚≠ê", "‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê"]
        }
        st.dataframe(pd.DataFrame(comparison), width='stretch')
    
    # TAB 4: Deep Learning & Transfer Learning
    with tab4:
        st.markdown("## üß† Deep Learning & Transfer Learning")
        st.info("‚ö†Ô∏è Mod√®les en cours de d√©veloppement sur branches s√©par√©es de l'√©quipe")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üî¨ TLModel (Transfer Learning)")
            st.markdown("**Branche** : `dev-fibonaccos-imagemodels`")
            
            st.markdown("#### Principe")
            st.write("""
            Utilisation d'architectures CNN pr√©-entra√Æn√©es (ImageNet) avec fine-tuning  
            sur le dataset Rakuten. Apprentissage par transfert pour exploiter les  
            repr√©sentations visuelles apprises sur des millions d'images.
            """)
            
            st.metric("Accuracy Test", "12.8%", delta="‚ö†Ô∏è En cours d'optimisation", delta_color="off")
            st.metric("Weighted F1", "9.3%")
            
            st.markdown("#### √âtat actuel")
            st.warning("""
            **Probl√®mes identifi√©s** :
            - Performance tr√®s faible (12.8% vs baseline 75%)
            - Possible sous-apprentissage ou probl√®me de convergence
            - Dataset peut-√™tre trop petit pour fine-tuning efficace
            - Hyperparam√®tres √† optimiser
            
            **Travaux en cours** :
            - Augmentation de donn√©es (rotations, flips, crop)
            - Test de diff√©rentes architectures (ResNet, EfficientNet, ViT)
            - Ajustement learning rate et epochs
            """)
        
        with col2:
            st.markdown("### üöÄ EfficientNet")
            st.markdown("**Branche** : `rbanat_dev_efficientNet`")
            
            st.markdown("#### Principe")
            st.write("""
            Architecture CNN state-of-the-art qui scale efficacement profondeur,  
            largeur et r√©solution. Meilleur rapport performance/co√ªt computationnel.
            """)
            
            st.metric("Statut", "En d√©veloppement", delta="üî• Prometteur")
            
            st.markdown("#### Caract√©ristiques")
            st.success("""
            **Avantages EfficientNet** :
            - Architecture optimale via Neural Architecture Search
            - Compound scaling (profondeur + largeur + r√©solution)
            - Performances SOTA sur ImageNet
            - Versions B0-B7 (scalabilit√©)
            
            **Application Rakuten** :
            - Embeddings visuels riches (2048D)
            - Reconnaissance patterns produits
            - Classification fine-grained
            """)
        
        st.markdown("### üìä Comparaison Approches")
        
        comparison_dl = {
            "Approche": ["TF-IDF + ML", "TLModel (CNN)", "EfficientNet (projet√©)", "Fusion Multimodale"],
            "Modalit√©": ["Texte", "Images", "Images", "Texte + Images"],
            "Accuracy": ["75.4%", "12.8%", "60-70% (estim√©)", "80-85% (estim√©)"],
            "Temps Training": ["4 min", "2-3h", "3-4h", "5-6h"],
            "Complexit√©": ["Faible", "√âlev√©e", "Tr√®s √©lev√©e", "Tr√®s √©lev√©e"],
            "Statut": ["‚úÖ Prod", "‚ö†Ô∏è Debug", "üî• Dev", "üéØ Futur"]
        }
        st.dataframe(pd.DataFrame(comparison_dl), width='stretch')
        
        st.markdown("### üí° Enseignements")
        
        st.markdown("""
        1. **Texte > Images** pour ce probl√®me : Les descriptions Rakuten sont tr√®s informatives,  
           les images seules insuffisantes (packaging similaire entre cat√©gories)
        
        2. **Deep Learning = Overhead** : Co√ªt computationnel √©lev√© (GPU requis) pour gain  
           modeste vs approche TF-IDF simple et efficace
        
        3. **Multimodalit√© prometteuse** : Combiner les deux modalit√©s pourrait donner  
           80-85% mais n√©cessite architecture fusion complexe
        
        4. **ROI √† consid√©rer** : 
           - SGDC : 75.4% en 4 min (CPU) ‚úÖ
           - CNN : 60-70% en 4h (GPU) avec fine-tuning ‚ö†Ô∏è
           - Fusion : 85% en 6h+ (GPU) ‚ùì
        """)
        
        st.info("""
        üí° **Recommandation** : Pour un MVP production, SGDC reste le meilleur choix.  
        Le deep learning est pertinent si :
        - Budget GPU disponible
        - Besoin d'exploiter pleinement les images  
        - Viser les 5-10 derniers points d'accuracy
        """)



















    # TAB 5: EfficientNet
    with tab5:
        st.markdown("## üß† EfficientNet")

        tab51, tab52, tab53 = st.tabs(["üîç M√©thodologie", "R√©sultats", "D√©monstration"])

        with tab51:
            st.markdown("## üåü M√©thodologie")
            st.write("""
            Cette section pr√©sente la m√©thodologie adopt√©e pour notre √©tude, d√©crivant en d√©tail les √©tapes cl√©s du processus de pr√©traitement des donn√©es, 
            le choix des mod√®les, l'optimisation des hyperparam√®tres et les m√©triques de performance utilis√©es.
            """)

            tab511, tab512, tab513, tab514 = st.tabs(["‚öôÔ∏è Pr√©-traitement des donn√©es", "üìâ Choix des mod√®les", "üîß Hyperparam√®tres", "üìä M√©triques"])

            with tab511:
                st.markdown("### ‚öôÔ∏è Pr√©-traitement des donn√©es")
                st.write("""
                Avant de commencer la phase d'entra√Ænement, un **pr√©traitement** rigoureux des donn√©es est essentiel. √âtant donn√© l'important d√©s√©quilibre des classes, 
                le **r√©√©chantillonnage** a √©t√© une √©tape cruciale. Plusieurs m√©thodes de r√©√©chantillonnage ont √©t√© envisag√©es :
                """)
                st.markdown("1. **Sous-√©chantillonnage des classes majoritaires** : R√©duit le nombre d'√©chantillons dans les classes sur-repr√©sent√©es.")
                st.markdown("2. **Sur√©chantillonnage des classes minoritaires** : Augmente le nombre d'√©chantillons dans les classes sous-repr√©sent√©es.")
                st.markdown("3. **Approche hybride** : Combine les deux strat√©gies pr√©c√©dentes.")
                st.write("Nous avons test√© √† la fois le sous-√©chantillonnage et l‚Äôapproche hybride, tout en laissant un pli intact pour la validation.")

            with tab512:
                st.markdown("### üìâ Choix des mod√®les")
                models_comparison = {
                    "Mod√®le": ["EfficientNet", "ResNet-50", "ResNet-101"],
                    "Description": [
                        "Architecture optimis√©e, excellente performance.",
                        "Facilite l‚Äôentra√Ænement de r√©seaux tr√®s profonds.",
                        "Bas√© sur des blocs r√©siduels, am√©liore le passage des gradients."
                    ]
                }
                st.dataframe(pd.DataFrame(models_comparison))

            with tab513:
                st.markdown("### üîß Hyperparam√®tres")
                st.write("""
                Nous nous sommes concentr√©s sur le **tuning du learning rate** de chaque mod√®le test√© dans une plage de **1e-2 √† 1e-5**.
                Les m√©thodes de r√©√©chantillonnage ont aussi √©t√© consid√©r√©es comme des hyperparam√®tres.
                """)

                st.markdown("### Configuration du Learning Rate")
                with st.expander("Voir la configuration", expanded=True):
                    st.code("""
            learning_rate = 1e-3  # Exemple de learning rate d√©fini
                    """, language="python")

            with tab514:
                st.markdown("### üìä M√©triques de comparaison")
                st.write("Le **F1-score pond√©r√©** a √©t√© retenu comme m√©trique principale, avec d'autres m√©triques comme la pr√©cision, le rappel, et l'accuracy.")
                
                metrics_comparison = {
                    "M√©trique": ["F1-score", "Pr√©cision", "Rappel", "Accuracy"],
                    "Description": [
                        "Int√®gre pr√©cision et rappel.",
                        "Pourcentage de vrais positifs parmi toutes les pr√©dictions positives.",
                        "Capacit√© √† identifier toutes les instances pertinentes.",
                        "Proportion globale de pr√©dictions correctes."
                    ]
                }
                st.dataframe(pd.DataFrame(metrics_comparison))

        with tab52:
                st.markdown("## R√©sultats")
                st.write("""
                Cette section pr√©sente les performances des mod√®les test√©s, mettant en lumi√®re l'impact des diff√©rentes approches de pr√©traitement, 
                des choix de mod√®les et de l'optimisation des hyperparam√®tres sur les m√©triques de performance.
                """)

                tab521, tab522, tab523, tab524, tab525 = st.tabs(["Impact du r√©√©chantillonnage", "Sur-apprentissage", "Jeu de test", "Matrice de confusion", "Interpr√©tabilit√© du mod√®le"])

                with tab521:
                    st.markdown("### Impact du r√©√©chantillonnage")
                    st.image("./reports/EfficientNet/figures/crossval_report.png", caption="Comparaison des exp√©riences")

                    st.write("""
                    Nous avons r√©alis√© un total de \*\*5 exp√©riences\*\* avec diff√©rentes approches de r√©√©chantillonnage. Le tableau ci-dessous pr√©sente les r√©sultats 
                    de ces m√©thodes au cours des validations crois√©es quant √† l‚Äôentra√Ænement d√©crit pr√©c√©demment.
                    """)

                    st.write("""
                    Il est clair que le \*\*sous-√©chantillonnage\*\* est l'approche qui donne les \*\*meilleurs r√©sultats\*\*, peu importe le \*\*learning rate\*\* utilis√©. 
                    Pour les autres m√©thodes, l'approche utilisant des \*\*rotations et des transpositions\*\* s'av√®re l√©g√®rement sup√©rieure √† celle du \*\*doublement des donn√©es\*\* dans tous les cas.
                    """)

                    st.write("""
                    L‚Äôapproche hybride obtient un \*\*F1-score\*\* de \*\*0,489\*\* en dupliquant les donn√©es contre \*\*0,494\*\* en appliquant des transformations. 
                    De m√™me, en absence de r√©√©chantillonnage, nous avons obtenu \*\*0,515\*\* avec duplication et \*\*0,528\*\* avec transformations.
                    """)

                    st.write("""
                    Il est int√©ressant de noter que ne pas r√©√©chantillonner semble √™tre la meilleure option dans notre cas, ce qui peut sembler contradictoire 
                    avec les bonnes pratiques de classification des donn√©es avec des classes d√©s√©quilibr√©es. Cette observation peut s'expliquer par le 
                    faible volume de donn√©es d'entra√Ænement. En effet, avec la m√©thode de sous-√©chantillonnage, nous n'avons finalement que \*\*864 donn√©es\*\* 
                    sur les \*\*4 000 initiales\*\*, r√©duisant significativement le volume de donn√©es disponibles.
                    """)

                    st.write("""
                    En revanche, l‚Äôapproche hybride a permis de conserver \*\*2 943 donn√©es\*\*, expliquant ainsi le meilleur score par rapport au sous-√©chantillonnage 
                    et les r√©sultats l√©g√®rement inf√©rieurs √† ceux sans r√©√©chantillonnage. On peut se demander si, avec un plus grand volume de donn√©es, 
                    l‚Äôapproche hybride surpasserait celle sans r√©√©chantillonnage.
                    """)

                with tab522:
                    st.markdown("### Sur-apprentissage")
                    st.image("./reports/EfficientNet/figures/learning_curve.png", caption="Courbe de sur-apprentissage")

                    st.write("""
                    Nous constatons un \*\*fort surapprentissage\*\*, ce qui √©tait attendu au vu des r√©sultats obtenus sur le jeu de validation. 
                    Avec l'utilisation de \*\*l'early stopping\*\*, le mod√®le final atteint un \*\*F1-score\*\* de \*\*0,590\*\* sur le jeu de validation 
                    apr√®s \*\*11 epochs\*\* et de \*\*0,901\*\* sur le jeu d‚Äôentra√Ænement.
                    """)

                    st.write("""
                    Un point important √† noter est que le \*\*F1-score\*\* sur le jeu de validation du mod√®le final a bien augment√©, passant de \*\*0,52\*\* √† \*\*0,59\*\*. 
                    Cela sugg√®re qu‚Äôavec plus de donn√©es, le surapprentissage pourrait se r√©duire de mani√®re significative.
                    """)

                with tab523:
                    st.markdown("### Jeu de test")
                    st.write("Jeu de test : 1 000 images")
                    st.write("F1-score : 0,564")
                    st.write("Pr√©cision : 0,568")
                    st.write("Rappel : 0,569")
                    st.write("Accuracy : 0,569")

                    st.write("""
                    Les scores obtenus sur le jeu de test sont coh√©rents avec ceux de la validation pr√©c√©dente, sans mauvaises surprises.
                    """)

                with tab524:
                    st.image("./reports/EfficientNet/figures/confusion_matrix.png", caption="Matrice de confusion")

                    st.write("""
                    D‚Äôapr√®s la matrice de confusion, certaines classes (1160, 2522, et en particulier 60) sont tr√®s bien pr√©dites par le mod√®le, 
                    avec un pourcentage de bonnes pr√©dictions sup√©rieur √† **85%**, tandis que d‚Äôautres (1560, 1140, 1180, 2905) peinent √† atteindre **30%**. 
                    Les autres classes affichent des taux variant entre **30%** et **76%**. En examinant de plus pr√®s la r√©partition des classes, il appara√Æt que les classes les mieux pr√©dites sont sous-repr√©sent√©es dans notre √©chantillon.
                    En particulier, la classe 60 ne compte que 10 images sur les 1 000 du jeu de test. Cela pourrait indiquer des caract√©ristiques d‚Äôimagerie uniques, rendant ainsi cette classe ¬´ facilement ¬ª pr√©visible, m√™me avec peu de donn√©es d‚Äôentra√Ænement (1%).
                    √Ä l'inverse, les classes 1180 et 2905 ne comprennent que 9 images chacune, sugg√©rant qu'elles n√©cessitent davantage de donn√©es d‚Äôentra√Ænement pour am√©liorer la capacit√© du mod√®le √† les pr√©dire correctement.
                    """)

                with tab525:
                    st.markdown("### Interpr√©tabilit√© du mod√®le")
                    st.write("""
                    En raison de contraintes de temps et de ressources, la section d√©di√©e √† l'interpr√©tabilit√© du mod√®le n'a pas pu √™tre approfondie. 
                    Cependant, l‚Äôinterpr√©tabilit√© est cruciale pour comprendre les d√©cisions prises par le mod√®le et √©valuer sa confiance dans ses pr√©dictions.
                    Dans de futurs travaux, il serait souhaitable d'explorer des m√©thodes telles que les **SHAP values** ou les **LIME** (Local Interpretable Model-agnostic Explanations) afin de mieux appr√©hender le fonctionnement du mod√®le.
                    """)

        with tab53:
            st.markdown("## D√©monstration")
            # Ajoutez un bouton pour ex√©cuter la fonction
            if st.button("Ex√©cuter la pr√©diction"):
                result = predict_efficientNet('./data/images/image_test/')  # Appelle la fonction
                st.success(result)  # Affiche le r√©sultat
                st.stop()

            # Bouton pour afficher les images
            if st.button("Afficher les images"):
                # Lister tous les fichiers d'image dans le r√©pertoire
                image_files = [f for f in os.listdir('./data/images/image_test/image_predict') if f.endswith(('jpg', 'png', 'jpeg'))]

                # V√©rifier s'il y a des images √† afficher
                if len(image_files) == 0:
                    st.write("Aucune image trouv√©e dans le dossier.")
                else:
                    # Afficher chaque image
                    for image_file in image_files:
                        # Construire le chemin complet de l'image
                        image_path = os.path.join('./data/images/image_test/image_predict', image_file)

                        # Charger et afficher l'image
                        image = Image.open(image_path)
                        st.image(image, caption=image_file, width=500)  # Affiche l'image avec le nom comme l√©gende























# PAGE 4: R√âSULTATS
elif page == "R√©sultats":
    st.markdown('<div class="main-header">üìä R√©sultats & Interpr√©tation</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    model_choice = st.selectbox(
        "S√©lectionner le mod√®le √† analyser",
        ["SGDCModel", "DecisionTreeModel", "RandomForest"],
        index=0
    )
    
    metrics = load_metrics(model_choice)
    
    if metrics:
        st.markdown("### üìà M√©triques Globales")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Accuracy", f"{metrics.get('accuracy', 0)*100:.1f}%")
        with col2:
            st.metric("Precision", f"{metrics.get('precision_weighted', 0)*100:.1f}%")
        with col3:
            st.metric("Recall", f"{metrics.get('recall_weighted', 0)*100:.1f}%")
        with col4:
            st.metric("F1-Score", f"{metrics.get('f1_weighted', 0)*100:.1f}%")
        
        if 'train_accuracy' in metrics:
            st.markdown("### üìä Analyse Overfitting")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Train Accuracy", f"{metrics.get('train_accuracy', 0)*100:.1f}%")
            with col2:
                st.metric("Test Accuracy", f"{metrics.get('accuracy', 0)*100:.1f}%")
            with col3:
                gap = metrics.get('overfitting_gap', 0) * 100
                delta_text = "‚úÖ Excellent" if gap < 5 else ("‚ö†Ô∏è Attention" if gap < 15 else "‚ùå Probl√®me")
                st.metric("Overfitting Gap", f"{gap:.1f}%", delta=delta_text)
        
        st.markdown("### üéØ Matrice de Confusion")
        cm_path = Path(f"models/{model_choice}/metrics/confusion_matrix.png")
        if cm_path.exists():
            cm_img = load_image(cm_path)
            if cm_img:
                st.image(cm_img, use_column_width=True, caption=f"Matrice de confusion - {model_choice}")
        else:
            st.warning(f"‚ö†Ô∏è Matrice de confusion non disponible pour {model_choice}")
        
        st.markdown("### üîç Analyse D√©taill√©e par Classe")
        
        report_path = Path(f"models/{model_choice}/metrics/classification_report.json")
        if report_path.exists():
            with open(report_path) as f:
                report = json.load(f)
            
            # Extraire donn√©es des classes
            classes_data = []
            for cls, metrics_cls in report.items():
                if cls not in ['accuracy', 'macro avg', 'weighted avg']:
                    classes_data.append({
                        "Classe": cls,
                        "Precision": f"{metrics_cls['precision']*100:.1f}%",
                        "Recall": f"{metrics_cls['recall']*100:.1f}%",
                        "F1-Score": f"{metrics_cls['f1-score']*100:.1f}%",
                        "Support": int(metrics_cls['support'])
                    })
            
            df_classes = pd.DataFrame(classes_data)
            df_classes['F1_numeric'] = df_classes['F1-Score'].str.rstrip('%').astype(float)
            df_classes = df_classes.sort_values('F1_numeric', ascending=False).drop('F1_numeric', axis=1)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üèÜ Top 5 Classes (Meilleures)")
                st.dataframe(df_classes.head(5), width='stretch', hide_index=True)
                st.success("Ces classes ont un vocabulaire tr√®s distinctif")
            
            with col2:
                st.markdown("#### üòû Bottom 5 Classes (Pires)")
                st.dataframe(df_classes.tail(5), width='stretch', hide_index=True)
                st.warning("Ces classes n√©cessitent plus de travail")
    else:
        st.error(f"‚ùå M√©triques non trouv√©es pour {model_choice}")
    
    st.markdown("### üí° Interpr√©tabilit√©")
    
    if "SGDC" in model_choice:
        st.write("""
        **SGDClassifier** offre une interpr√©tabilit√© **moyenne** via :
        - Coefficients des features (poids de chaque mot)
        - Feature importance globale
        - Analyse des mots les plus discriminants par classe
        
        ‚ö†Ô∏è **Limites** : 16K coefficients difficiles √† interpr√©ter individuellement
        """)
    else:
        st.write("""
        **Arbre de D√©cision** offre une interpr√©tabilit√© **maximale** via :
        - R√®gles IF/THEN explicites et lisibles par humain
        - Visualisation graphique de l'arbre complet
        - Tra√ßabilit√© compl√®te de chaque d√©cision
        - Export texte des r√®gles (tree_structure.txt)
        
        ‚úÖ **Avantage** : Chaque pr√©diction est 100% explicable
        """)

# PAGE 5: D√âMO LIVE
elif page == "Demo":
    st.markdown('<div class="main-header">üéÆ D√©mo Live - Testez le Mod√®le</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    st.info("""
    üí° **Testez le mod√®le SGDC en temps r√©el !**  
    Entrez la description d'un produit et le mod√®le pr√©dira sa cat√©gorie.
    """)
    
    # Charger le mod√®le et les transformers
    @st.cache_resource
    def load_model_and_transformers():
        """Charge le mod√®le SGDC et les transformers"""
        try:
            import pickle
            
            # Charger le mod√®le
            with open('models/SGDCModel/artefacts/sgdc_model.pkl', 'rb') as f:
                model = pickle.load(f)
            
            # Charger le label encoder
            with open('models/SGDCModel/artefacts/label_encoder.pkl', 'rb') as f:
                label_encoder = pickle.load(f)
            
            # Charger les transformers (pour TF-IDF)
            with open('data/clean/sgdc_model/transformers.pkl', 'rb') as f:
                transformers = pickle.load(f)
            
            return model, label_encoder, transformers
        except Exception as e:
            st.error(f"Erreur lors du chargement : {e}")
            return None, None, None
    
    model, label_encoder, transformers = load_model_and_transformers()
    
    if model is not None:
        st.success("‚úÖ Mod√®le SGDC charg√© avec succ√®s (75.4% accuracy)")
        
        # Exemples pr√©d√©finis
        st.markdown("### üìù Exemples √† tester")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìö Exemple Livre"):
                st.session_state.demo_text = "Harry Potter et la Chambre des Secrets livre broch√© neuf de J.K. Rowling √©dition Gallimard fantasy roman jeunesse"
        
        with col2:
            if st.button("üéÆ Exemple Jeu Vid√©o"):
                st.session_state.demo_text = "FIFA 24 jeu vid√©o console PS5 PlayStation sport football simulation EA Sports neuf sous blister"
        
        with col3:
            if st.button("üì± Exemple High-Tech"):
                st.session_state.demo_text = "iPhone 15 Pro smartphone Apple 256GB noir titanium t√©l√©phone mobile 5G cam√©ra 48MP √©cran OLED"
        
        # Zone de texte
        st.markdown("### ‚úçÔ∏è Votre description produit")
        
        default_text = st.session_state.get('demo_text', '')
        user_input = st.text_area(
            "Entrez la description d'un produit :",
            value=default_text,
            height=100,
            placeholder="Ex: Livre Harry Potter neuf, Console PS5, Smartphone Samsung Galaxy..."
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            predict_button = st.button("üöÄ Pr√©dire", type="primary", use_container_width=True)
        with col2:
            st.write("")  # Spacer
        
        if predict_button and user_input.strip():
            with st.spinner("üîÑ Pr√©diction en cours..."):
                try:
                    # Preprocessing du texte - CR√âER UN DATAFRAME
                    import pandas as pd
                    text_vectorizer = transformers['text_vectorizer']
                    
                    # Cr√©er DataFrame avec les bonnes colonnes (designation et description)
                    input_df = pd.DataFrame({
                        'designation': [user_input],
                        'description': [user_input]  # On utilise le m√™me texte pour les deux
                    })
                    
                    text_features = text_vectorizer.transform(input_df)
                    
                    # Comme on n'a pas d'image, on ajoute des features images nulles (192 dimensions)
                    import numpy as np
                    import scipy.sparse as sp
                    image_features = np.zeros((1, 192))
                    
                    # Combiner texte + image
                    if sp.issparse(text_features):
                        text_features_dense = text_features.toarray()
                    else:
                        text_features_dense = text_features
                    
                    combined_features = np.hstack([text_features_dense, image_features])
                    
                    # Pr√©diction
                    prediction_encoded = model.predict(combined_features)
                    prediction_proba = model.predict_proba(combined_features)
                    
                    # D√©coder la pr√©diction
                    prediction = label_encoder.inverse_transform(prediction_encoded)[0]
                    
                    # Afficher les r√©sultats
                    st.markdown("---")
                    st.markdown("## üéØ R√©sultat de la Pr√©diction")
                    
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.markdown(f"### Cat√©gorie Pr√©dite")
                        st.markdown(f"<div style='font-size:3rem;text-align:center;color:#FF6B6B;font-weight:bold;'>{prediction}</div>", unsafe_allow_html=True)
                        
                        max_proba = prediction_proba[0][prediction_encoded[0]]
                        st.metric("Confiance", f"{max_proba*100:.1f}%")
                    
                    with col2:
                        st.markdown("### üìä Top 5 Probabilit√©s")
                        
                        # Obtenir les top 5 pr√©dictions
                        top_5_idx = np.argsort(prediction_proba[0])[-5:][::-1]
                        top_5_classes = label_encoder.inverse_transform(top_5_idx)
                        top_5_proba = prediction_proba[0][top_5_idx]
                        
                        for i, (cls, prob) in enumerate(zip(top_5_classes, top_5_proba)):
                            if i == 0:
                                st.success(f"**{cls}** : {prob*100:.2f}%")
                            else:
                                st.info(f"{cls} : {prob*100:.2f}%")
                    
                    # Explication
                    st.markdown("---")
                    st.markdown("### üí° Comment √ßa marche ?")
                    
                    st.write("""
                    1. **Preprocessing** : Votre texte est nettoy√© et converti en vecteur TF-IDF (16K dimensions)
                    2. **Features images** : Simul√©es √† z√©ro car pas d'image fournie (192 dimensions)
                    3. **Pr√©diction** : Le mod√®le SGDC calcule un score pour chacune des 27 classes
                    4. **R√©sultat** : La classe avec le score le plus √©lev√© est retourn√©e
                    """)
                    
                    # Afficher les mots-cl√©s d√©tect√©s
                    if hasattr(text_vectorizer, 'get_feature_names_out'):
                        feature_names = text_vectorizer.get_feature_names_out()
                        text_vector = text_features.toarray()[0]
                        
                        # Trouver les mots avec TF-IDF non nul
                        non_zero_idx = np.where(text_vector > 0)[0]
                        if len(non_zero_idx) > 0:
                            keywords = [(feature_names[i], text_vector[i]) for i in non_zero_idx]
                            keywords.sort(key=lambda x: x[1], reverse=True)
                            
                            st.markdown("### üîë Mots-cl√©s d√©tect√©s (Top 10)")
                            keywords_text = ", ".join([f"**{word}** ({score:.3f})" for word, score in keywords[:10]])
                            st.markdown(keywords_text)
                
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la pr√©diction : {e}")
                    st.exception(e)
        
        elif predict_button:
            st.warning("‚ö†Ô∏è Veuillez entrer une description de produit")
        
        # L√©gende des cat√©gories
        st.markdown("---")
        st.markdown("### üìö Codes des 27 Cat√©gories Rakuten")
        
        with st.expander("Voir tous les codes (signification exacte non document√©e)"):
            st.warning("""
            ‚ö†Ô∏è **Note** : Ces codes sont des identifiants internes Rakuten.  
            La signification pr√©cise de chaque code n'est pas fournie dans le dataset.  
            Les cat√©gories ci-dessous sont des suppositions bas√©es sur l'analyse des descriptions.
            """)
            
            categories_info = {
                "10": "Cat√©gorie 10 - Livres/M√©dias",
                "40": "Cat√©gorie 40 - Jeux vid√©o anciens",
                "50": "Cat√©gorie 50 - Accessoires gaming",
                "60": "Cat√©gorie 60 - Consoles de jeux",
                "1140": "Cat√©gorie 1140 - Figurines/Collectibles",
                "1160": "Cat√©gorie 1160 - Livres (fiction/litt√©rature)",
                "1180": "Cat√©gorie 1180 - Livres jeunesse/BD",
                "1280": "Cat√©gorie 1280 - Jeux vid√©o",
                "1281": "Cat√©gorie 1281 - Jeux PC",
                "1300": "Cat√©gorie 1300 - Accessoires jeux vid√©o",
                "1301": "Cat√©gorie 1301 - Jeux de soci√©t√©",
                "1302": "Cat√©gorie 1302 - Accessoires consoles",
                "1320": "Cat√©gorie 1320 - Cartes √† collectionner",
                "1560": "Cat√©gorie 1560 - Mobilier",
                "1920": "Cat√©gorie 1920 - Linge de maison",
                "1940": "Cat√©gorie 1940 - Alimentation/√âpicerie",
                "2060": "Cat√©gorie 2060 - D√©coration int√©rieure",
                "2220": "Cat√©gorie 2220 - Animalerie",
                "2280": "Cat√©gorie 2280 - Magazines/Presse",
                "2403": "Cat√©gorie 2403 - Livres (autre type)",
                "2462": "Cat√©gorie 2462 - Jeux et jouets vintage",
                "2522": "Cat√©gorie 2522 - Papeterie/Fournitures",
                "2582": "Cat√©gorie 2582 - Mobilier ext√©rieur",
                "2583": "Cat√©gorie 2583 - Piscines et accessoires",
                "2585": "Cat√©gorie 2585 - Outillage/Bricolage",
                "2705": "Cat√©gorie 2705 - Livres anciens/Collection",
                "2905": "Cat√©gorie 2905 - Jeux de construction"
            }
            
            st.info("""
            üí° **Pourquoi plusieurs codes pour "Livres" ?**  
            Les codes 10, 1160, 2403, 2705 semblent tous li√©s aux livres mais correspondent  
            probablement √† des sous-cat√©gories diff√©rentes (genre, √¢ge, format, etc.).  
            Sans la documentation Rakuten officielle, on ne peut que deviner la distinction exacte.
            """)
            
            cols = st.columns(3)
            for idx, (code, desc) in enumerate(categories_info.items()):
                with cols[idx % 3]:
                    st.write(f"**{code}** : {desc}")
    
    else:
        st.error("‚ùå Impossible de charger le mod√®le. V√©rifiez que les fichiers sont pr√©sents.")
        st.info("""
        Fichiers requis :
        - `models/SGDCModel/artefacts/sgdc_model.pkl`
        - `models/SGDCModel/artefacts/label_encoder.pkl`
        - `data/clean/sgdc_model/transformers.pkl`
        """)

# PAGE 6: OUVERTURE
elif page == "Ouverture":
    st.markdown('<div class="main-header">üîÆ Ouverture & Perspectives</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    st.markdown("### üöÄ Am√©liorations Possibles")
    
    st.info("""
    üí° **Note** : Plusieurs de ces am√©liorations sont **d√©j√† en cours** par l'√©quipe sur d'autres branches !
    - Branche `dev-fibonaccos-imagemodels` : Transfer Learning (TLModel)
    - Branche `rbanat_dev_efficientNet` : EfficientNet
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üñºÔ∏è Am√©liorer les Features Images")
        st.info("""
        **Actuellement** : Histogrammes RGB (192 features)
        
        **Am√©liorations propos√©es** :
        - Embeddings ResNet50/EfficientNet (2048D)
        - Features HOG + SIFT combin√©es
        - Fine-tuning CNN sur dataset Rakuten
        - Vision Transformers (ViT)
        
        **Gain attendu** : +5 √† 10 points d'accuracy
        """)
        
        st.markdown("#### ü§ñ Ensemble Methods")
        st.info("""
        **Voting Classifier** combinant :
        - SGDC (75.4%)
        - Random Forest (50.8%)
        - XGBoost (60% estim√©)
        
        **Vote pond√©r√© ou majoritaire**
        
        **Gain attendu** : +3 √† 5 points
        """)
    
    with col2:
        st.markdown("#### üìù Am√©liorer le Texte")
        st.info("""
        **Actuellement** : TF-IDF (16K features)
        
        **Am√©liorations propos√©es** :
        - CamemBERT embeddings (768D contextuels)
        - FlauBERT fine-tun√© sur Rakuten
        - Sentence-BERT fran√ßais
        - GPT pour augmentation de donn√©es
        
        **Gain attendu** : +5 √† 15 points d'accuracy
        """)
        
        st.markdown("#### ‚ö° Optimisations Production")
        st.info("""
        **Pour le d√©ploiement** :
        - ONNX runtime (3x plus rapide)
        - Quantization int8
        - Feature hashing (m√©moire r√©duite)
        - API REST avec FastAPI
        
        **R√©sultat** : Production-ready avec scalabilit√©
        """)
    
    st.markdown("### üéØ Roadmap Id√©ale (si plus de temps)")
    
    roadmap = {
        "Phase": ["Phase 1", "Phase 2", "Phase 3", "Phase 4", "Phase 5"],
        "Action": ["Baseline SGDC ‚úÖ", "Embeddings CNN", "CamemBERT texte", "Fusion multimodale", "Production API"],
        "Accuracy cible": ["75%", "80%", "85%", "88%", "90%+"],
        "Dur√©e estim√©e": ["Fait", "1 semaine", "2 semaines", "1 semaine", "2 semaines"],
        "Priorit√©": ["‚úÖ", "üî• Haute", "üî• Haute", "üìà Moyenne", "üöÄ Basse"]
    }
    st.table(pd.DataFrame(roadmap))
    
    st.markdown("### üèÜ Benchmark Industrie")
    
    benchmark_data = {
        "Approche": [
            "Random Guess (hasard)",
            "TF-IDF + ML classique (notre projet)",
            "CNN + RNN",
            "BERT + CNN multimodal",
            "√âtat de l'art (ensemble deep learning)"
        ],
        "Accuracy": ["3.7%", "75.4%", "82%", "87%", "92%"],
        "Complexit√©": ["Nulle", "Faible", "Moyenne", "√âlev√©e", "Tr√®s √©lev√©e"],
        "Temps training": ["-", "4 min", "2h", "6h", "12h+"],
        "Ressources": ["-", "CPU seul", "1 GPU", "Multi-GPU", "Cluster GPU"]
    }
    st.dataframe(pd.DataFrame(benchmark_data), width='stretch')
    
    st.success("""
    üí° **Conclusion** : Notre approche TF-IDF + SGDClassifier repr√©sente un excellent compromis  
    performance/complexit√© pour un MVP (Minimum Viable Product).
    
    **Gain vs hasard** : +71.7 points  
    **√âcart vs deep learning** : -11 points seulement  
    **Rapport ressources** : 100x moins de ressources que deep learning
    """)

# PAGE 6: CONCLUSION
else:  # Conclusion
    st.markdown('<div class="main-header">‚úÖ Conclusion</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    st.markdown("### üéØ Objectifs Atteints")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.success("""
        **‚úÖ Classification 27 classes**
        - 75.4% accuracy (SGDC)
        - 50.8% accuracy (Random Forest)
        - 40.9% accuracy (DecisionTree)
        """)
    with col2:
        st.success("""
        **‚úÖ Approche Multimodale**
        - Texte via TF-IDF
        - Images via histogrammes RGB
        - Fusion features r√©ussie
        """)
    with col3:
        st.success("""
        **‚úÖ Mod√®les Robustes**
        - Pas d'overfitting
        - Scalables
        - Interpr√©tables
        """)
    
    st.markdown("### üìä R√©sultats Cl√©s en Chiffres")
    
    results_summary = {
        "M√©trique": ["Meilleur mod√®le", "Accuracy", "Gain vs hasard", "Temps training", "Interpr√©tabilit√©"],
        "Valeur": ["SGDClassifier", "75.4%", "+71.7 points", "4 minutes", "Moyenne"],
        "Contexte": ["Mod√®le lin√©aire", "3 sur 4 corrects", "vs 3.7% random", "Sur CPU", "Via coefficients"]
    }
    st.table(pd.DataFrame(results_summary))
    
    st.markdown("### üí™ Points Forts du Projet")
    
    col1, col2 = st.columns(2)
    with col1:
        st.info("""
        **Aspects Techniques**
        - Pipeline preprocessing robuste et r√©utilisable
        - Optimisation hyperparam√®tres syst√©matique
        - Validation train/test rigoureuse
        - Documentation compl√®te du code
        - Comparaison 3 approches diff√©rentes
        """)
    with col2:
        st.info("""
        **Aspects M√©tier**
        - Solution adapt√©e au contexte e-commerce
        - Scalable √† des millions de produits
        - Temps de r√©ponse acceptable (<1s)
        - Explicabilit√© pour audit/conformit√©
        - Co√ªt infrastructure faible (CPU)
        """)
    
    st.markdown("### üîÑ Autocritique & Limites Identifi√©es")
    
    st.warning("""
    **Limites actuelles** :
    - Features images tr√®s basiques (histogrammes) ‚Üí Potentiel CNN non exploit√©
    - Pas de deep learning (contrainte GPU/temps de formation)
    - 5 classes tr√®s difficiles (F1 < 20%) n√©cessitent attention particuli√®re
    - D√©s√©quilibre classes partiellement r√©solu seulement
    - Pas de validation crois√©e (k-fold) faute de temps
    """)
    
    st.markdown("### üéì Principaux Apprentissages")
    
    st.markdown("""
    1. **Le texte est roi en e-commerce** : Les descriptions sont plus discriminantes que les images pour ce probl√®me
    2. **Simple peut largement suffire** : TF-IDF + SGDC rivalise avec des approches bien plus complexes
    3. **R√©gularisation est cruciale** : √âviter l'overfitting est plus important que performance brute
    4. **Importance des trade-offs** : Performance vs Interpr√©tabilit√©, Complexit√© vs Temps, Co√ªt vs Gain
    5. **Valeur d'une baseline solide** : Avoir un mod√®le ML simple avant de passer au deep learning
    """)
    
    st.markdown("### üôè Remerciements")
    st.write("""
    - **DataScientest** pour la formation et l'accompagnement
    - **Rakuten France** pour la mise √† disposition du dataset
    - **L'√©quipe projet** pour la collaboration et l'entraide
    - **Les formateurs** pour leur expertise et leurs conseils
    """)
    
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; padding: 3rem 0;'>
        <h1>üéâ Merci de votre attention ! üéâ</h1>
        <h3>Des questions ?</h3>
    </div>
    """, unsafe_allow_html=True)

# FOOTER (toujours affich√©)
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #888; padding: 1rem 0;'>
    <strong>Classification Multimodale Rakuten</strong> | DataScientest 2025 | Made with ‚ù§Ô∏è and Streamlit
</div>
""", unsafe_allow_html=True)

