import streamlit as st
import pandas as pd
import json
from pathlib import Path


def render():
    """Affiche la section SGDClassifier (1m30 de pr√©sentation)"""
    
    # Introduction
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üéØ Principe de Fonctionnement")
        st.write("""
        **SGDClassifier** = Mod√®le **lin√©aire** qui apprend progressivement.
        
        **Concept** :
        - Trace 27 hyperplans dans un espace √† 16 192 dimensions
        - Chaque hyperplan s√©pare une cat√©gorie des autres
        - Apprentissage incr√©mental exemple par exemple (ou mini-batches)
        - Optimisation par descente de gradient stochastique
        
        **Particularit√©** : Excellent pour haute dimensionnalit√© et grands datasets
        """)
    
    with col2:
        # Charger m√©triques
        try:
            metrics_path = Path("C:/Users/HP/DataScientest/PROJET/deep_learning_rakuten/git/rakuten-multimodal-classification/Rakuten_Streamlit_Presentation/models/SGDCModel/metrics/metrics_summary.json")
            if metrics_path.exists():
                with open(metrics_path) as f:
                    metrics = json.load(f)
                
                st.metric("Accuracy", f"{metrics.get('accuracy', 0)*100:.1f}%", delta="Test set")
                st.metric("F1-Score", f"{metrics.get('f1_weighted', 0)*100:.1f}%", delta="Weighted")
                st.metric("Precision", f"{metrics.get('precision_weighted', 0)*100:.1f}%")
            else:
                st.metric("Accuracy", "75.4%", delta="Test set")
                st.metric("F1-Score", "74.8%", delta="Weighted")
                st.metric("Precision", "75.2%")
        except:
            st.metric("Accuracy", "75.4%", delta="Test set")
            st.metric("F1-Score", "74.8%", delta="Weighted")
    
    # Hyperparam√®tres optimis√©s
    st.markdown("### ‚öôÔ∏è Configuration Hyperparam√®tres")
    
    st.write("Optimis√©s par **GridSearch exhaustif** sur 45 combinaisons :")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.code("""
# Fonction de perte et r√©gularisation
loss = 'log_loss'          # Perte logistique
penalty = 'elasticnet'     # L1 + L2
alpha = 0.00005           # Faible p√©nalisation
l1_ratio = 0.15           # 15% L1, 85% L2
        """, language="python")
        
        st.info("""
        üí° **ElasticNet** combine :
        - **L1** (Lasso) : S√©lection features
        - **L2** (Ridge) : R√©gularisation douce
        """)
    
    with col2:
        st.code("""
# Param√®tres d'optimisation
max_iter = 150            # 150 epochs
learning_rate = 'optimal' # Adaptatif
early_stopping = True     # Arr√™t si stagnation
class_weight = 'balanced' # √âquilibrage auto
        """, language="python")
        
        st.success("""
        ‚úÖ **Early stopping** :
        √âvite surapprentissage en surveillant validation set
        """)
    
    # Donn√©es d'entra√Ænement
    st.markdown("### üìä Donn√©es d'Entra√Ænement")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("√âchantillons", "10 000", delta="Train optimis√©")
    with col2:
        st.metric("Features Texte", "16 000", delta="TF-IDF bigrammes")
    with col3:
        st.metric("Features Image", "192", delta="Histogrammes RGB")
    with col4:
        st.metric("Total Features", "16 192", delta="Haute dimension")
    
    st.success("""
    ‚úÖ **Dataset optimal** : 10k √©chantillons + 16k features = Meilleur compromis  
    performance/temps pour SGDC (4 minutes training sur CPU)
    """)
    
    # R√©sultats
    st.markdown("### üìà R√©sultats")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Accuracy", "75.4%", delta="3/4 corrects")
    with col2:
        st.metric("F1-Score", "74.8%", delta="Weighted")
    with col3:
        st.metric("Temps Training", "4 min", delta="CPU")
    
    # Analyse de l'overfitting
    st.markdown("### üîç Analyse G√©n√©ralisation")
    
    col1, col2, col3 = st.columns(3)
    
    try:
        metrics_path = Path("C:/Users/HP/DataScientest/PROJET/deep_learning_rakuten/git/rakuten-multimodal-classification/Rakuten_Streamlit_Presentation/models/SGDCModel/metrics/metrics_summary.json")
        if metrics_path.exists():
            with open(metrics_path) as f:
                metrics = json.load(f)
            
            with col1:
                st.metric("Train Accuracy", f"{metrics.get('train_accuracy', 0.78)*100:.1f}%")
            with col2:
                st.metric("Test Accuracy", f"{metrics.get('accuracy', 0.754)*100:.1f}%")
            with col3:
                gap = abs(metrics.get('train_accuracy', 0.78) - metrics.get('accuracy', 0.754)) * 100
                st.metric("√âcart Train/Test", f"{gap:.1f}%", delta="‚úÖ Excellent" if gap < 5 else "‚ö†Ô∏è Attention")
    except:
        with col1:
            st.metric("Train Accuracy", "78.0%")
        with col2:
            st.metric("Test Accuracy", "75.4%")
        with col3:
            st.metric("√âcart Train/Test", "2.6%", delta="‚úÖ Excellent")
    
    st.success("""
    ‚úÖ **Excellente g√©n√©ralisation** : √âcart < 3% gr√¢ce √† la r√©gularisation ElasticNet et early stopping
    """)
    
    # Points forts et limites
    st.markdown("### ‚öñÔ∏è Points Forts & Limites")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **‚úÖ Points Forts**
        
        1. **Performance √©lev√©e** : 75.4% accuracy
        2. **Scalabilit√©** : Millions d'exemples possibles
        3. **Rapidit√©** : 4 minutes training (CPU)
        4. **Haute dimensionnalit√©** : Excelle avec 16k features
        5. **Pas de surapprentissage** : R√©gularisation efficace
        6. **Apprentissage incr√©mental** : Streaming de donn√©es
        7. **Faible m√©moire** : Mod√®le lin√©aire compact
        """)
    
    with col2:
        st.warning("""
        **‚ö†Ô∏è Limites**
        
        1. **Lin√©arit√© uniquement** : Patterns non-lin√©aires ignor√©s
        2. **Sensible au preprocessing** : Qualit√© TF-IDF critique
        3. **Features images basiques** : Histogrammes RGB (< 2%)
        4. **Interpr√©tabilit√©** : 16k coefficients difficiles √† lire
        5. **Tuning n√©cessaire** : GridSearch sur 45 combinaisons
        6. **Plafond de performance** : 75% max pour approche lin√©aire
        7. **Cat√©gories proches** : Confusion si lexique similaire
        """)
    
    # Pourquoi SGDC fonctionne bien
    st.markdown("### üèÜ Pourquoi SGDC Fonctionne Bien Ici")
    
    strengths = {
        "Facteur Cl√©": [
            "Haute dimensionnalit√©",
            "Nature du probl√®me",
            "Taille du dataset",
            "Ressources limit√©es"
        ],
        "Explication": [
            "16k features textuelles = espace o√π SGDC excelle naturellement",
            "Classification texte TF-IDF souvent lin√©airement s√©parable",
            "10k √©chantillons = taille id√©ale pour SGDC (ni trop petit, ni √©norme)",
            "4 min CPU vs plusieurs heures GPU pour Deep Learning"
        ],
        "Impact": ["+++", "+++", "++", "++"]
    }
    st.dataframe(pd.DataFrame(strengths), use_container_width=True, hide_index=True)
    
    # Mots-cl√©s discriminants
    st.markdown("### üîë Mots-Cl√©s Discriminants")
    
    st.info("""
    **Top Features** (bas√© sur coefficients SGDC) :
    
    Le mod√®le identifie automatiquement les mots/bigrammes les plus importants :
    - **Cat√©gorie 2583** (Piscines) : "piscine", "gonflable", "intex"
    - **Cat√©gorie 1280** (Jeux vid√©o) : "ps4", "playstation", "jeu vid√©o"
    - **Cat√©gorie 1920** (Linge) : "housse couette", "coton", "parure"
    - **Cat√©gorie 2585** (Bricolage) : "perceuse", "batterie", "makita"
    
    Les features images contribuent ~2% seulement (texte domine).
    """)
    
    # Conclusion
    st.markdown("### üéØ Conclusion")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **üìä Performance**
        - Accuracy : **75.4%** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
        - F1-Score : **74.8%** (weighted)
        - Gain vs hasard : **+71.7 points**
        - Temps training : **4 minutes**
        - G√©n√©ralisation : **2.6% gap**
        """)
    
    with col2:
        st.success("""
        **üí° Utilisation Optimale**
        
        SGDC est **ID√âAL** pour :
        - Classification texte haute dimension
        - Projets avec contraintes CPU
        - MVP production rapide
        - Datasets moyens √† grands (10k+)
        - Besoin de scalabilit√©
        """)
    
    st.write("""
    **Enseignement cl√©** : Un mod√®le lin√©aire bien optimis√© (SGDC) peut atteindre d'excellentes 
    performances sur de la classification texte multimodale, tout en restant rapide et √©conomique.
    
    **3 produits sur 4 correctement class√©s** - Performance remarquable pour un mod√®le aussi simple !
    """)
