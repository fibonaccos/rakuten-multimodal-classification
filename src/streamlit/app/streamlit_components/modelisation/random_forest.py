import streamlit as st
import pandas as pd
import json
from pathlib import Path


def render():
    """Affiche la section Random Forest (1m30 de pr√©sentation)"""
    
    # Introduction
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üéØ Principe de Fonctionnement")
        st.write("""
        **Random Forest** = Ensemble de **50 arbres de d√©cision** qui votent collectivement.
        
        **Concept** :
        - Chaque arbre est entra√Æn√© sur un √©chantillon al√©atoire des donn√©es
        - Chaque arbre utilise un sous-ensemble al√©atoire de features
        - Pr√©diction finale = vote majoritaire des 50 arbres
        
        **Avantage** : R√©duit drastiquement le surapprentissage vs arbre unique
        """)
    
    with col2:
        # Charger m√©triques
        try:
            metrics_path = Path("C:/Users/HP/DataScientest/PROJET/deep_learning_rakuten/git/rakuten-multimodal-classification/Rakuten_Streamlit_Presentation/models/RandomForest/metrics/metrics_summary.json")
            if metrics_path.exists():
                with open(metrics_path) as f:
                    metrics = json.load(f)
                
                st.metric("Accuracy", f"{metrics.get('accuracy', 0)*100:.1f}%", delta="Test set")
                st.metric("F1-Score", f"{metrics.get('f1_weighted', 0)*100:.1f}%", delta="Weighted")
                st.metric("√âcart Train/Test", f"{metrics.get('overfitting_gap', 0)*100:.1f}%", delta="‚úÖ Excellent")
            else:
                st.metric("Accuracy", "50.8%", delta="Test set")
                st.metric("F1-Score", "48.5%", delta="Weighted")
                st.metric("√âcart Train/Test", "4.2%", delta="‚úÖ Excellent")
        except:
            st.metric("Accuracy", "50.8%", delta="Test set")
            st.metric("F1-Score", "48.5%", delta="Weighted")
    
    # Hyperparam√®tres
    st.markdown("### ‚öôÔ∏è Configuration Hyperparam√®tres")
    
    st.write("Optimis√©s par **GridSearch** pour √©quilibrer performance et g√©n√©ralisation :")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.code("""
# Param√®tres de l'ensemble
n_estimators = 50          # 50 arbres
class_weight = 'balanced'  # √âquilibrage auto

# Param√®tres de chaque arbre
criterion = 'gini'         # Mesure impuret√©
max_depth = 20            # Profondeur max
        """, language="python")
    
    with col2:
        st.code("""
# Param√®tres de r√©gularisation
min_samples_split = 30    # Min pour split
min_samples_leaf = 15     # Min par feuille
max_features = 0.7        # 70% features/split
ccp_alpha = 0.001         # Pruning l√©ger
        """, language="python")
    
    st.info("""
    üí° **Justification** : Ces hyperparam√®tres r√©sultent d'une optimisation par GridSearch 
    pour trouver le meilleur √©quilibre entre performance et g√©n√©ralisation.
    """)
    
    # Donn√©es d'entra√Ænement
    st.markdown("### üìä Donn√©es d'Entra√Ænement")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("√âchantillons", "5 000", delta="R√©duit pour vitesse")
    with col2:
        st.metric("Features Texte", "10 000", delta="TF-IDF")
    with col3:
        st.metric("Features Image", "192", delta="Histogrammes RGB")
    
    st.warning("""
    ‚ö†Ô∏è **Dataset r√©duit** : Pour des raisons de temps de calcul, le Random Forest est entra√Æn√© 
    sur un √©chantillon de 5000 produits. Cela impacte la performance finale.
    """)
    
    # R√©sultats
    st.markdown("### üìà R√©sultats")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Accuracy", "50.8%", delta="1/2 corrects")
    with col2:
        st.metric("F1-Score", "48.5%", delta="Weighted")
    with col3:
        st.metric("Temps Training", "30 sec", delta="CPU")
    
    st.info("""
    **Performance mod√©r√©e** : 50.8% d'accuracy sur le test set. Am√©lioration significative 
    vs un arbre unique (~40%), mais reste limit√© pour ce probl√®me haute dimension.
    """)
    
    # Points forts et limites
    st.markdown("### ‚öñÔ∏è Points Forts & Limites")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **‚úÖ Points Forts**
        
        1. **Robustesse** : Moins de surapprentissage qu'un seul arbre
        2. **Interpr√©tabilit√©** : Feature importance disponible ‚≠ê‚≠ê‚≠ê‚≠ê
        3. **Excellente g√©n√©ralisation** : Gap seulement 4.2%
        4. **Parall√©lisable** : Arbres ind√©pendants
        5. **G√®re bien le bruit** : Vote majoritaire lisse les erreurs
        6. **Rapide** : 30 secondes training
        7. **Patterns non-lin√©aires** : Peut capturer des relations complexes
        """)
    
    with col2:
        st.error("""
        **‚ùå Limites**
        
        1. **Haute dimensionnalit√©** : Souffre avec 10k features
        2. **Performance mod√©r√©e** : 50.8% accuracy
        3. **Espace de recherche explosif** : 10k features √† √©valuer
        4. **Complexit√©** : 50 arbres difficiles √† interpr√©ter individuellement
        5. **M√©moire** : Stocke 50 arbres complets
        6. **Scalabilit√© limit√©e** : Pas optimal pour millions d'exemples
        7. **Dataset r√©duit** : 5k √©chantillons = vocabulaire incomplet
        """)
    
    # Pourquoi performance limit√©e
    st.markdown("### ü§î Pourquoi Performance Limit√©e ?")
    
    reasons = {
        "Facteur Limitant": [
            "Haute dimensionnalit√© (10k features)",
            "Nature du probl√®me",
            "Dataset r√©duit (5k)",
            "Type de features"
        ],
        "Explication": [
            "Arbres souffrent du curse of dimensionality - trop de features √† √©valuer",
            "Classification texte souvent lin√©airement s√©parable - arbres cherchent du non-lin√©aire",
            "Moins de donn√©es = vocabulaire incomplet, patterns moins appris",
            "TF-IDF sparse haute dimension inadapt√© aux arbres de d√©cision"
        ],
        "Impact": ["---", "--", "--", "-"]
    }
    st.dataframe(pd.DataFrame(reasons), use_container_width=True, hide_index=True)
    
    # Feature importance
    st.markdown("### üîç Feature Importance")
    
    st.info("""
    **Avantage majeur** : Random Forest identifie automatiquement les mots les plus discriminants.
    
    **Top Features Importantes** (approximatif bas√© sur TF-IDF) :
    - Mots sp√©cifiques aux cat√©gories (ex: "piscine", "console", "livre")
    - Bigrammes informatifs (ex: "jeu vid√©o", "linge maison")
    - Features images contribuent peu (~2% importance totale)
    
    **Utilit√©** : Permet de comprendre quels mots sont les plus utiles pour la classification.
    """)
    
    # Conclusion
    st.markdown("### üéØ Conclusion")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **üìä Performance**
        - Accuracy : **50.8%**
        - F1-Score : **48.5%** (weighted)
        - Gain vs arbre unique : **~+10 pts**
        - G√©n√©ralisation : **4.2% gap**
        - Temps : **30 secondes**
        """)
    
    with col2:
        st.success("""
        **üí° Utilisation Recommand√©e**
        
        Random Forest est **pertinent** pour :
        - Projets n√©cessitant interpr√©tabilit√©
        - Features < 1000 dimensions
        - Budgets computationnels limit√©s
        - Baseline rapide avant deep learning
        - Analyse feature importance
        """)
    
    st.write("""
    **Enseignement cl√©** : Random Forest est un excellent mod√®le pour de nombreux probl√®mes, 
    mais souffre face √† la haute dimensionnalit√© textuelle (10k features). Son point fort 
    reste l'**interpr√©tabilit√©** et la **robustesse** avec une excellente g√©n√©ralisation (pas d'overfitting).
    """)
