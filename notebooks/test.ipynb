{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb9e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ac32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_update.csv')\n",
    "y_train = pd.read_csv('Y_train_CVw08PX.csv')\n",
    "\n",
    "df = X_train.copy()\n",
    "df['prdtypecode'] = y_train['prdtypecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa1023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_fr = set([\n",
    "    \"le\", \"la\", \"les\", \"un\", \"une\", \"des\", \"de\", \"du\", \"au\", \"aux\", \"en\",\n",
    "    \"et\", \"√†\", \"pour\", \"par\", \"avec\", \"sur\", \"dans\", \"ce\", \"ces\", \"se\", \"sa\",\n",
    "    \"son\", \"ses\", \"qui\", \"que\", \"quoi\", \"dont\", \"o√π\", \"comme\", \"est\", \"sont\",\n",
    "    \"il\", \"elle\", \"ils\", \"elles\", \"nous\", \"vous\", \"ne\", \"pas\", \"plus\", \"moins\",\n",
    "    \"ou\", \"mais\", \"donc\", \"or\", \"ni\", \"car\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea91039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', text)\n",
    "        if not unicodedata.combining(c)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b4df67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des descriptions nettoy√©es :\n",
      "                                  description_propre\n",
      "0  olivia personalisiertes notizbuch seiten punkt...\n",
      "1  journal arts art marche salon art asiatique pa...\n",
      "2  pilot style touch pen marque speedlink stylet ...\n",
      "3  peluche donald europe disneyland marionnette d...\n",
      "4  luc eacute grandeur veut organiser jeu guerre ...\n",
      "5  afrique contemporaine hiver dossier japon afrique\n",
      "6            christof bildungsprozessen auf der spur\n",
      "7  conquerant classique cahier seyes incolorecouv...\n",
      "8                    puzzle scooby doo poster pieces\n",
      "9  tente pliante pro pvc soyez particulier votre ...\n"
     ]
    }
   ],
   "source": [
    "def nettoyage(row):\n",
    "    text = row['description']\n",
    "\n",
    "    if pd.isnull(text) or str(text).strip() == \"\":\n",
    "        text = row['designation']\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = remove_accents(text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)  # supprimer HTML\n",
    "    text = re.sub(r'[^a-z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø√±√¶≈ì\\s]', ' ', text)  # garder lettres\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # espaces propres\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords_fr and len(t) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "\n",
    "df['description_propre'] = df.apply(nettoyage, axis=1) #application du nettoyage √† la colonne description\n",
    "\n",
    "print(\"Aper√ßu des descriptions nettoy√©es :\")\n",
    "print(df[['description_propre']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6ccb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape : (84916, 10000)\n"
     ]
    }
   ],
   "source": [
    "#Vectorisation\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,       \n",
    "    ngram_range=(1, 2),       \n",
    "    stop_words='english'      \n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(df['description_propre'])\n",
    "\n",
    "print(\"TF-IDF shape :\", X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0dfe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple fictif de matrice TF-IDF :\n",
      "    adapte  adapte votre   adhesif       ans   arriere       art      arts  \\\n",
      "0  0.00000      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.00000      0.000000  0.000000  0.182861  0.000000  0.500922  0.297919   \n",
      "2  0.07023      0.114624  0.088852  0.000000  0.070574  0.000000  0.000000   \n",
      "3  0.00000      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.00000      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "    aussi      bleu     bonus  ...   tactile     tenue     touch      tous  \\\n",
      "0  0.0000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.0000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.0633  0.059271  0.110711  ...  0.078763  0.101049  0.198196  0.000000   \n",
      "3  0.0000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.0000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.142402   \n",
      "\n",
      "        tre     tres      veut     votre  votre main       wii  \n",
      "0  0.000000  0.00000  0.000000  0.000000    0.000000  0.000000  \n",
      "1  0.000000  0.00000  0.000000  0.000000    0.000000  0.000000  \n",
      "2  0.000000  0.05258  0.000000  0.039201    0.110597  0.291294  \n",
      "3  0.000000  0.00000  0.000000  0.000000    0.000000  0.000000  \n",
      "4  0.249986  0.00000  0.271112  0.000000    0.000000  0.000000  \n",
      "\n",
      "[5 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "sample_tfidf = X_tfidf[:5].toarray()\n",
    "df_tfidf_sample = pd.DataFrame(sample_tfidf, columns=feature_names)\n",
    "df_tfidf_sample = df_tfidf_sample.loc[:, (df_tfidf_sample != 0).any(axis=0)]\n",
    "print(\"Exemple fictif de matrice TF-IDF :\")\n",
    "print(df_tfidf_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf072e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Peeta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'tokens'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m keywords_by_prdtypecode = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m df[\u001b[33m'\u001b[39m\u001b[33mprdtypecode\u001b[39m\u001b[33m'\u001b[39m].unique():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     tokens = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprdtypecode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.sum()\n\u001b[32m      5\u001b[39m     freq = Counter(tokens).most_common(\u001b[32m10\u001b[39m)\n\u001b[32m      6\u001b[39m     keywords_by_prdtypecode[code] = freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Peeta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Peeta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'tokens'"
     ]
    }
   ],
   "source": [
    "#Extraire les mots les plus fr√©quents pour chaque prdtypecode\n",
    "keywords_by_prdtypecode = {}\n",
    "for code in df['prdtypecode'].unique():\n",
    "    description_propre = df[df['prdtypecode'] == code]['description_propre'].sum()\n",
    "    freq = Counter(description_propre).most_common(10)\n",
    "    keywords_by_prdtypecode[code] = freq\n",
    "\n",
    "for code, keywords in sorted(keywords_by_prdtypecode.items()):\n",
    "    print(f\"\\nüîπ prdtypecode = {code}\")\n",
    "    for word, count in keywords:\n",
    "        print(f\"{word:15} ‚Üí {count} fois\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
